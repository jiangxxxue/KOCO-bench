# ğŸ’¬ Chat-Anything  
> Chat with your data, the web, and everything in between.

---

### ğŸš€ Introduction  

**Chat-Anything** is my custom evolution of **RAG-Anything** and **rag-web-ui** â€” a unified, intelligent chat system built to interact with *any* knowledge source.  

It combines **Retrieval-Augmented Generation (RAG)** with a modern **web interface**, enhanced by **MCP (Model Context Protocol)** to support **live web search** and context injection from real-time data.  

In simple terms:  
> Itâ€™s a chat app that can reason, search, and learn â€” all in one place.  

---

### âœ¨ Why I Built It  

While experimenting with **RAG-Anything**, I realized how powerful it could be when paired with a smooth web UI and dynamic context updates.  

So I decided to merge:  
- ğŸ§© **RAG-Anything** â†’ for its modular multimodal RAG pipeline.  
- ğŸ–¥ï¸ **rag-web-ui** â†’ for its clean and interactive frontend.  
- ğŸŒ **MCP (Web Search)** â†’ to let the model pull *fresh* info directly from the internet.  

Now, **Chat-Anything** lets you explore any topic â€” powered by your own files, your knowledge base, and the entire web.

---

### ğŸ§  Key Features  

- ğŸ” **Integrated Web Search (MCP)**  
  Seamlessly fetch and summarize live data from the internet in real time.  

- ğŸ“š **RAG-Enhanced Answers**  
  Combines local knowledge bases and embeddings for context-aware responses.  

- ğŸ’¬ **Unified Web Interface**  
  A beautiful, fast chat UI (from rag-web-ui) for an effortless experience.  

- ğŸ“ **Multi-Source Data Loading**  
  Ingest PDFs, text files, URLs, and online results â€” all unified under one context.  

- âš™ï¸ **Context Memory Management**  
  Keeps track of your conversation state and source materials intelligently.  

- ğŸ§© **Open & Extendable**  
  Add your own LLM providers, vector DBs, or tools â€” fully modular and customizable.

---

### ğŸ§° Tech Stack  

| Layer | Technologies |
|-------|---------------|
| **Frontend** | Next.js, React, TailwindCSS |
| **Backend** | FastAPI, Python |
| **RAG Engine** | LangChain, LlamaIndex, FAISS / Pinecone |
| **Protocol Layer** | MCP (Model Context Protocol) |
| **Integrations** | OpenAI API, Local file loaders, Web Search tools |
| **Deployment** | Docker, uvicorn, nginx |

---

### ğŸ—ï¸ Architecture Overview  

    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚     Frontend       â”‚  â†’  Next.js (rag-web-ui)
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
             â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚     Backend        â”‚  â†’  FastAPI + LangChain
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
             â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚        RAG Engine          â”‚
    â”‚ (RAG-Anything + MCP Layer) â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚           â”‚
      â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”
      â”‚ Vector Storeâ”‚ â”‚ Web Searchâ”‚
      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

---

### âš¡ Getting Started  

#### 1. Clone the repository  
```bash
git clone https://github.com/yourusername/chat-anything.git
cd chat-anything
# Backend
cd backend
pip install -r requirements.txt

# Frontend
cd ../frontend
npm install
# Set environment variables
OPENAI_API_KEY=your_key
SEARCH_API_KEY=your_key
VECTOR_DB_URL=your_url

# Run locally
 # Run backend
uvicorn main:app --reload

# Run frontend
npm run dev
ğŸ’¡ Example Use Cases

Ask for a real-time summary of todayâ€™s tech news.

Upload a PDF or documentation and chat about it.

Compare AI models or frameworks using fresh web data.

Mix local knowledge with live internet sources in one conversation.

ğŸ—ºï¸ Roadmap

 Multi-user sessions

 Persistent memory across chats

 Enhanced analytics & citation display

 Custom RAG pipelines via UI

 Support for multimodal input (images, audio)

ğŸ™ Acknowledgements

Huge thanks to the creators of:

RAG-Anything

rag-web-ui

Model Context Protocol (MCP)

And to the open-source community that keeps pushing the boundaries of what RAGs can do.

ğŸ§¾ License

MIT License Â© 2025 â€” Developed with â¤ï¸ by Zakaria Eisa

