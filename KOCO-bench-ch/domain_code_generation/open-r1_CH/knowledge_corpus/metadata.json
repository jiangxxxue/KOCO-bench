{
  "framework_name": "Open R1",
  "framework_description": "Open R1 is a fully open reproduction of DeepSeek-R1, designed to replicate and extend the reasoning capabilities of large language models through a multi-stage training pipeline. The project implements supervised fine-tuning (SFT) and Group Relative Policy Optimization (GRPO) to train models on reasoning tasks spanning mathematics, coding, and science. It features synthetic data generation using Distilabel, integration with high-performance inference engines (vLLM), support for distributed training with DeepSpeed and Accelerate, comprehensive evaluation pipelines using LightEval, and production-ready recipes for training models from 0.6B to 70B+ parameters. The project has successfully reproduced DeepSeek's distilled models and released the Mixture-of-Thoughts dataset containing 350k verified reasoning traces, along with specialized datasets for competitive programming (CodeForces-CoTs) and mathematics (OpenR1-Math-220k)."
}