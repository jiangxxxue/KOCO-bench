# NeMo 项目概述

## 1. 总体概述

NeMo 是一个用于构建和训练大规模语言模型、多模态模型和语音模型的框架，集成了 TensorRT Model Optimizer 进行模型优化。其核心能力在于提供完整的模型训练、推理和优化流程，支持量化、剪枝、蒸馏等模型优化技术。通过集成 ModelOpt 框架，NeMo 能够实现高效的模型压缩和加速，特别适用于生产环境中的模型部署。

## 2. 核心功能

### 2.1 模型量化 (Quantization)
支持多种量化算法，包括 FP8、INT8、INT4 等精度，通过 ModelOpt 的量化工具实现模型压缩和加速。

### 2.2 模型剪枝 (Pruning)
提供结构化剪枝功能，支持宽度剪枝（隐藏层维度、注意力头数量）和深度剪枝（层数减少），通过重要性指标进行层选择。

### 2.3 知识蒸馏 (Distillation)
实现教师-学生模型的知识转移，支持 logits 蒸馏和中间层蒸馏，通过 ModelOpt 的蒸馏框架优化训练过程。

### 2.4 模型导出
支持多种导出格式，包括 TensorRT-LLM、HuggingFace 和 NeMo 原生格式，便于不同部署环境的使用。

### 2.5 推理优化
通过 ModelOpt 集成实现高效的推理加速，支持多种硬件平台和部署场景。

