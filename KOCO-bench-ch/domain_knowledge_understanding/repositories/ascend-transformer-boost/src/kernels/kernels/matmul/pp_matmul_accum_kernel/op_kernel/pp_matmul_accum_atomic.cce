/*
 * Copyright (c) 2024 Huawei Technologies Co., Ltd.
 * This file is a part of the CANN Open Software.
 * Licensed under CANN Open Software License Agreement Version 1.0 (the "License").
 * Please refer to the License for details. You may not use this file except in compliance with the License.
 * THIS SOFTWARE IS PROVIDED ON AN "AS IS" BASIS, WITHOUT WARRANTIES OF ANY KIND, EITHER EXPRESS OR IMPLIED,
 * INCLUDING BUT NOT LIMITED TO NON-INFRINGEMENT, MERCHANTABILITY, OR FITNESS FOR A PARTICULAR PURPOSE.
 * See LICENSE in the root of the software repository for the full text of the License.
 */

#ifdef __CCE_KT_TEST__
using __bf16 = bfloat16_t;
#include "stub_def.h"
#include "stub_fun.h"
#else
#define __aicore__ [aicore]
#endif
#include "kernels/matmul/tiling/tiling_data.h"
#include "kernels/utils/kernel/common.h"
#include "kernels/utils/kernel/iterator.h"
#include "kernels/utils/kernel/mem.h"
#include "kernels/utils/kernel/mma.h"
#include "kernels/utils/kernel/utils.h"

constexpr uint32_t L0_PINGPONG_BUFFER_LEN = 16384;
constexpr uint32_t L1_PINGPONG_BUFFER_LEN = 131072;
constexpr uint32_t CONST_16 = 16;
constexpr uint32_t CONST_256 = 256;
constexpr uint64_t ND2NZ_STRIDE_LIMIT = 65536;

template <uint32_t SwizzleDir, bool TA, bool TB, typename InDtype, typename OutDtype, typename AccumDtype>
class PpMatmulAccumAtomic {
public:
    __aicore__ explicit PpMatmulAccumAtomic(){};
    __force_inline__ __aicore__ void Init(__gm__ uint8_t *__restrict__ a,
                                          __gm__ uint8_t *__restrict__ b,
                                          __gm__ uint8_t *__restrict__ c,
                                          __gm__ uint8_t *__restrict__ tiling_data);
    __force_inline__ __aicore__ void GetTileIdx(const uint32_t index, uint64_t &m_idx, uint64_t &n_idx);
    __force_inline__ __aicore__ void Run();

private:
    AscendC::GlobalTensor<InDtype> gm_a;
    AscendC::GlobalTensor<InDtype> gm_b;
    AscendC::GlobalTensor<OutDtype> gm_c;
    AscendC::LocalTensor<InDtype> l1_base_a;
    AscendC::LocalTensor<InDtype> l1_base_b;
    AscendC::LocalTensor<InDtype> l0a_base;
    AscendC::LocalTensor<InDtype> l0b_base;
    AscendC::LocalTensor<AccumDtype> l0c_buf;

    uint32_t num_core{0};
    uint32_t batch_size{0};
    uint32_t m{0};
    uint32_t k{0};
    uint32_t n{0};
    uint32_t m0{0};
    uint32_t k0{0};
    uint32_t n0{0};
    uint32_t m_loop{0};
    uint32_t n_loop{0};
    uint32_t k_loop{0};
    uint32_t core_loop{0};
    uint32_t core_idx{0};
    uint32_t swizzle_cnt{1};
    uint32_t ping_flag{0};
    uint32_t en_shuffle_k{0};
};

template <uint32_t SwizzleDir, bool TA, bool TB, typename InDtype, typename OutDtype, typename AccumDtype>
__aicore__ __force_inline__ void
PpMatmulAccumAtomic<SwizzleDir, TA, TB, InDtype, OutDtype, AccumDtype>::Init(__gm__ uint8_t *__restrict__ a,
                                                                             __gm__ uint8_t *__restrict__ b,
                                                                             __gm__ uint8_t *__restrict__ c,
                                                                             __gm__ uint8_t *__restrict__ tiling_data)
{
    gm_a.SetGlobalBuffer(reinterpret_cast<__gm__ InDtype *>(a));
    gm_b.SetGlobalBuffer(reinterpret_cast<__gm__ InDtype *>(b));
    gm_c.SetGlobalBuffer(reinterpret_cast<__gm__ OutDtype *>(c));
    auto gm_tiling_data = reinterpret_cast<__gm__ AsdOps::PpMatmulTilingData *>(tiling_data);
    batch_size = gm_tiling_data->batch;
    m = gm_tiling_data->m;
    k = gm_tiling_data->k;
    n = gm_tiling_data->n;
    m0 = gm_tiling_data->m0;
    k0 = gm_tiling_data->k0;
    n0 = gm_tiling_data->n0;
    m_loop = gm_tiling_data->mLoop;
    k_loop = gm_tiling_data->kLoop;
    n_loop = gm_tiling_data->nLoop;
    core_loop = gm_tiling_data->coreLoop;
    swizzle_cnt = gm_tiling_data->swizzlCount;
    en_shuffle_k = gm_tiling_data->enShuffleK;
    AsdopsBuffer<ArchType::ASCEND_V220> buf;
    l1_base_a = buf.GetBuffer<BufferType::ASCEND_CB, InDtype>(0);
    l1_base_b = buf.GetBuffer<BufferType::ASCEND_CB, InDtype>(RoundUp<CONST_256>((uint64_t)m0 * k0 * sizeof(InDtype)));
    l0a_base = buf.GetBuffer<BufferType::ASCEND_L0A, InDtype>(0);
    l0b_base = buf.GetBuffer<BufferType::ASCEND_L0B, InDtype>(0);
    l0c_buf = buf.GetBuffer<BufferType::ASCEND_L0C, AccumDtype>(0);
    num_core = AscendC::GetBlockNum();
    core_idx = AscendC::GetBlockIdx();
    ping_flag = 1;
}

template <uint32_t SwizzleDir, bool TA, bool TB, typename InDtype, typename OutDtype, typename AccumDtype>
__aicore__ __force_inline__ void PpMatmulAccumAtomic<SwizzleDir, TA, TB, InDtype, OutDtype, AccumDtype>::GetTileIdx(
    const uint32_t index, uint64_t &m_idx, uint64_t &n_idx)
{
    uint32_t in_batch_idx = index % (m_loop * n_loop);
    if constexpr (SwizzleDir == 0) { // Zn
        uint32_t tile_block_loop = (m_loop + swizzle_cnt - 1) / swizzle_cnt;
        uint32_t tile_block_idx = in_batch_idx / (swizzle_cnt * n_loop);
        uint32_t in_tile_block_idx = in_batch_idx % (swizzle_cnt * n_loop);

        uint32_t n_row = swizzle_cnt;
        if (tile_block_idx == tile_block_loop - 1) {
            n_row = m_loop - swizzle_cnt * tile_block_idx;
        }
        m_idx = tile_block_idx * swizzle_cnt + in_tile_block_idx % n_row;
        n_idx = in_tile_block_idx / n_row;
        if (tile_block_idx % 2 != 0) {
            n_idx = n_loop - n_idx - 1;
        }
    } else if constexpr (SwizzleDir == 1) { // Nz
        uint32_t tile_block_loop = (n_loop + swizzle_cnt - 1) / swizzle_cnt;
        uint32_t tile_block_idx = in_batch_idx / (swizzle_cnt * m_loop);
        uint32_t in_tile_block_idx = in_batch_idx % (swizzle_cnt * m_loop);

        uint32_t n_col = swizzle_cnt;
        if (tile_block_idx == tile_block_loop - 1) {
            n_col = n_loop - swizzle_cnt * tile_block_idx;
        }
        m_idx = in_tile_block_idx / n_col;
        n_idx = tile_block_idx * swizzle_cnt + in_tile_block_idx % n_col;
        if (tile_block_idx % 2 != 0) {
            m_idx = m_loop - m_idx - 1;
        }
    }
}

template <uint32_t SwizzleDir, bool TA, bool TB, typename InDtype, typename OutDtype, typename AccumDtype>
__aicore__ __force_inline__ void PpMatmulAccumAtomic<SwizzleDir, TA, TB, InDtype, OutDtype, AccumDtype>::Run()
{
    using InTensor = AscendC::LocalTensor<InDtype>;
    using CopyGmToCbuf = gm_to_l1<ArchType::ASCEND_V220, InDtype, DataFormat::ND, DataFormat::ND>;
    using CopyGmToCbufNd2Nz = gm_to_l1<ArchType::ASCEND_V220, InDtype, DataFormat::ND, DataFormat::NZ>;
    using LoadCbufToCa = l1_to_l0_a<ArchType::ASCEND_V220, InDtype, TA, DataFormat::ZN, DataFormat::ZZ>;
    using LoadCbufToCb = l1_to_l0_b<ArchType::ASCEND_V220, InDtype, TB, DataFormat::ZN, DataFormat::NZ>;
    using Mad = mmad<ArchType::ASCEND_V220, InDtype, InDtype, AccumDtype, false>;
    using CopyCcToGm = l0c_to_gm<ArchType::ASCEND_V220, DataFormat::ND, OutDtype, AccumDtype>;

    SET_FLAG(MTE1, MTE2, EVENT_ID0);
    SET_FLAG(MTE1, MTE2, EVENT_ID1);
    SET_FLAG(MTE1, MTE2, EVENT_ID2);
    SET_FLAG(MTE1, MTE2, EVENT_ID3);
    SET_FLAG(M, MTE1, EVENT_ID0);
    SET_FLAG(M, MTE1, EVENT_ID1);
    SET_FLAG(FIX, M, EVENT_ID0);

    for (uint32_t loop_idx = core_idx; loop_idx < core_loop; loop_idx += num_core) {
        uint64_t m_idx = 0, n_idx = 0;
        GetTileIdx(loop_idx, m_idx, n_idx);
        uint64_t batch_idx = loop_idx / n_loop / m_loop;

        uint64_t offset_a, offset_b, offset_a_next, offset_b_next;
        uint64_t offset_c = batch_idx * m * n + m_idx * m0 * n + n_idx * n0;
        uint32_t m_actual = (m_idx == (m_loop - 1)) ? (m - m_idx * m0) : m0;
        uint32_t n_actual = (n_idx == (n_loop - 1)) ? (n - n_idx * n0) : n0;
        uint32_t m_round = (m_actual + CONST_16 - 1) / CONST_16 * CONST_16;
        uint32_t n_round = (n_actual + CONST_16 - 1) / CONST_16 * CONST_16;
        uint32_t mn_max = m_round > n_round ? m_round : n_round;
        uint32_t k_part_len = L0_PINGPONG_BUFFER_LEN / mn_max / CONST_16 * CONST_16;
        uint64_t shuffle_k = en_shuffle_k ? core_idx % k_loop : 0;
        if (TA) {
            offset_a = batch_idx * m * k + shuffle_k * k0 * m + m_idx * m0;
        } else {
            offset_a = batch_idx * m * k + m_idx * m0 * k + shuffle_k * k0;
        }

        if (TB) {
            offset_b = batch_idx * k * n + n_idx * n0 * k + shuffle_k * k0;
        } else {
            offset_b = batch_idx * k * n + shuffle_k * k0 * n + n_idx * n0;
        }

        uint32_t k_actual = (shuffle_k == k_loop - 1) ? k - shuffle_k * k0 : k0;
        uint32_t k_round = (k_actual + CONST_16 - 1) / CONST_16 * CONST_16;

        InTensor l1_buf_a = ping_flag ? l1_base_a : l1_base_a[L1_PINGPONG_BUFFER_LEN];
        InTensor l1_buf_b = ping_flag ? l1_base_b : l1_base_b[L1_PINGPONG_BUFFER_LEN];
        InTensor l0a_buf = ping_flag ? l0a_base : l0a_base[L0_PINGPONG_BUFFER_LEN];
        InTensor l0b_buf = ping_flag ? l0b_base : l0b_base[L0_PINGPONG_BUFFER_LEN];

        event_t event_id = ping_flag ? EVENT_ID0 : EVENT_ID1;

        if (loop_idx == core_idx) {
            WAIT_FLAG(MTE1, MTE2, event_id);
            // Load matrix A to L1
            if ((m == 1) || (m_actual == 1 && !TA)) {
                CopyGmToCbuf(l1_buf_a,       // dst
                             gm_a[offset_a], // src
                             1,              // nTileActual
                             CONST_16,       // nTileCeil
                             1,              // nVal
                             k_actual,       // kTileActual
                             k_round,        // kTileCeil
                             k);             // dVal
            } else {
                if (TA) {
                    CopyGmToCbufNd2Nz(l1_buf_a,       // dst
                                      gm_a[offset_a], // src
                                      k_actual,       // nTileActual
                                      k_round,        // nTileCeil
                                      k,              // nVal
                                      m_actual,       // dTileActual
                                      m_round,        // dTileCeil
                                      m);             // dVal
                } else {
                    CopyGmToCbufNd2Nz(l1_buf_a,       // dst
                                      gm_a[offset_a], // src
                                      m_actual,       // nTileActual
                                      m_round,        // nTileCeil
                                      m,              // nVal
                                      k_actual,       // dTileActual
                                      k_round,        // dTileCeil
                                      k);             // dVal
                }
            }
            SET_FLAG(MTE2, MTE1, event_id);
            // Load matrix B to L1
            WAIT_FLAG(MTE1, MTE2, event_id + 2);
            if (TB) {
                CopyGmToCbufNd2Nz(l1_buf_b,       // dst
                                  gm_b[offset_b], // src
                                  n_actual,       // nTileActual
                                  n_round,        // nTileCeil
                                  n,              // nVal
                                  k_actual,       // dTileActual
                                  k_round,        // dTileCeil
                                  k);             // dVal
            } else {
                CopyGmToCbufNd2Nz(l1_buf_b,       // dst
                                  gm_b[offset_b], // src
                                  k_actual,       // nTileActual
                                  k_round,        // nTileCeil
                                  k,              // nVal
                                  n_actual,       // dTileActual
                                  n_round,        // dTileCeil
                                  n);             // dVal
            }
            SET_FLAG(MTE2, MTE1, event_id + 2);
        }

        for (uint64_t k_idx = 0; k_idx < k_loop; k_idx++) {
            shuffle_k = en_shuffle_k ? (k_idx + core_idx) % k_loop : k_idx;
            uint32_t k_actual = (shuffle_k == (k_loop - 1)) ? (k - shuffle_k * k0) : k0;
            uint32_t k_round = (k_actual + CONST_16 - 1) / CONST_16 * CONST_16;
            uint32_t k_part_loop = (k_actual + k_part_len - 1) / k_part_len;

            InTensor l1_buf_a = ping_flag ? l1_base_a : l1_base_a[L1_PINGPONG_BUFFER_LEN];
            InTensor l1_buf_b = ping_flag ? l1_base_b : l1_base_b[L1_PINGPONG_BUFFER_LEN];
            auto event_id = ping_flag ? EVENT_ID0 : EVENT_ID1;

            if (k_idx < k_loop - 1) {
                uint64_t shuffle_k_next = en_shuffle_k ? (core_idx + k_idx + 1) % k_loop : k_idx + 1;
                if (TA) {
                    offset_a_next = batch_idx * m * k + shuffle_k_next * k0 * m + m_idx * m0;
                } else {
                    offset_a_next = batch_idx * m * k + m_idx * m0 * k + shuffle_k_next * k0;
                }

                if (TB) {
                    offset_b_next = batch_idx * k * n + n_idx * n0 * k + shuffle_k_next * k0;
                } else {
                    offset_b_next = batch_idx * k * n + shuffle_k_next * k0 * n + n_idx * n0;
                }

                uint32_t k_actual_next = (shuffle_k_next == (k_loop - 1)) ? (k - shuffle_k_next * k0) : k0;
                uint32_t k_round_next = (k_actual_next + CONST_16 - 1) / CONST_16 * CONST_16;

                InTensor l1_buf_a_next = (1 - ping_flag) ? l1_base_a : l1_base_a[L1_PINGPONG_BUFFER_LEN];
                InTensor l1_buf_b_next = (1 - ping_flag) ? l1_base_b : l1_base_b[L1_PINGPONG_BUFFER_LEN];
                event_t event_id_next = (1 - ping_flag) ? EVENT_ID0 : EVENT_ID1;

                WAIT_FLAG(MTE1, MTE2, event_id_next);
                // Load matrix A to L1
                if ((m == 1) || (m_actual == 1 && !TA)) {
                    CopyGmToCbuf(l1_buf_a_next,       // dst
                                 gm_a[offset_a_next], // src
                                 m_actual,            // nTileActual
                                 m_round,             // nTileCeil
                                 m,                   // nVal
                                 k_actual_next,       // kTileActual
                                 k_round_next,        // kTileCeil
                                 k);                  // dVal
                } else {
                    if (TA) {
                        CopyGmToCbufNd2Nz(l1_buf_a_next,       // dst
                                          gm_a[offset_a_next], // src
                                          k_actual_next,       // nTileActual
                                          k_round_next,        // nTileCeil
                                          k,                   // nVal
                                          m_actual,            // kTileActual
                                          m_round,             // kTileCeil
                                          m);                  // dVal
                    } else {
                        CopyGmToCbufNd2Nz(l1_buf_a_next,       // dst
                                          gm_a[offset_a_next], // src
                                          m_actual,            // nTileActual
                                          m_round,             // nTileCeil
                                          m,                   // nVal
                                          k_actual_next,       // dTileActual
                                          k_round_next,        // dTileCeil
                                          k);                  // dVal
                    }
                }
                SET_FLAG(MTE2, MTE1, event_id_next);

                // Load matrix B to L1
                WAIT_FLAG(MTE1, MTE2, event_id_next + 2);
                if (TB) {
                    CopyGmToCbufNd2Nz(l1_buf_b_next,       // dst
                                      gm_b[offset_b_next], // src
                                      n_actual,            // nTileActual
                                      n_round,             // nTileCeil
                                      n,                   // nVal
                                      k_actual_next,       // dTileActual
                                      k_round_next,        // dTileCeil
                                      k);                  // dVal
                } else {
                    CopyGmToCbufNd2Nz(l1_buf_b_next,       // dst
                                      gm_b[offset_b_next], // src
                                      k_actual_next,       // nTileActual
                                      k_round_next,        // nTileCeil
                                      k,                   // nVal
                                      n_actual,            // dTileActual
                                      n_round,             // dTileCeil
                                      n);                  // dVal
                }
                SET_FLAG(MTE2, MTE1, event_id_next + 2);
            }

            if (k_idx == k_loop - 1 && loop_idx + num_core < core_loop) {
                uint64_t m_idx_next = 0, n_idx_next = 0;
                GetTileIdx(loop_idx + num_core, m_idx_next, n_idx_next);
                uint64_t b_idx_next = (loop_idx + num_core) / n_loop / m_loop;
                uint64_t shuffle_k_next = en_shuffle_k ? core_idx % k_loop : 0;
                uint32_t m_actual_next = (m_idx_next == (m_loop - 1)) ? (m - m_idx_next * m0) : m0;
                uint32_t n_actual_next = (n_idx_next == (n_loop - 1)) ? (n - n_idx_next * n0) : n0;
                uint32_t m_round_next = (m_actual_next + CONST_16 - 1) / CONST_16 * CONST_16;
                uint32_t n_round_next = (n_actual_next + CONST_16 - 1) / CONST_16 * CONST_16;
                uint32_t k_actual_next = (shuffle_k_next == k_loop - 1) ? k - shuffle_k_next * k0 : k0;
                uint32_t k_round_next = (k_actual_next + CONST_16 - 1) / CONST_16 * CONST_16;
                if (TA) {
                    offset_a_next = b_idx_next * m * k + shuffle_k_next * k0 * m + m_idx_next * m0;
                } else {
                    offset_a_next = b_idx_next * m * k + m_idx_next * m0 * k + shuffle_k_next * k0;
                }
                if (TB) {
                    offset_b_next = b_idx_next * k * n + n_idx_next * n0 * k + shuffle_k_next * k0;
                } else {
                    offset_b_next = b_idx_next * k * n + shuffle_k_next * k0 * n + n_idx_next * n0;
                }
                InTensor l1_buf_a_next = (1 - ping_flag) ? l1_base_a : l1_base_a[L1_PINGPONG_BUFFER_LEN];
                InTensor l1_buf_b_next = (1 - ping_flag) ? l1_base_b : l1_base_b[L1_PINGPONG_BUFFER_LEN];
                event_t event_id_next = (1 - ping_flag) ? EVENT_ID0 : EVENT_ID1;

                WAIT_FLAG(MTE1, MTE2, event_id_next);
                // Load matrix A to L1
                if (m == 1 || m_actual_next == 1 && !TA) {
                    CopyGmToCbuf(l1_buf_a_next,       // dst
                                 gm_a[offset_a_next], // src
                                 m_actual_next,       // nTileActual
                                 m_round_next,        // nTileCeil
                                 m,                   // nVal
                                 k_actual_next,       // kTileActual
                                 k_round_next,        // kTileCeil
                                 k);                  // dVal
                } else {
                    if (TA) {
                        CopyGmToCbufNd2Nz(l1_buf_a_next,       // dst
                                          gm_a[offset_a_next], // src
                                          k_actual_next,       // nTileActual
                                          k_round_next,        // nTileCeil
                                          k,                   // nVal
                                          m_actual_next,       // dTileActual
                                          m_round_next,        // dTileCeil
                                          m);                  // dVal
                    } else {
                        CopyGmToCbufNd2Nz(l1_buf_a_next,       // dst
                                          gm_a[offset_a_next], // src
                                          m_actual_next,       // nTileActual
                                          m_round_next,        // nTileCeil
                                          m,                   // nVal
                                          k_actual_next,       // dTileActual
                                          k_round_next,        // dTileCeil
                                          k);                  // dVal
                    }
                }
                SET_FLAG(MTE2, MTE1, event_id_next);

                // Load matrix B to L1
                WAIT_FLAG(MTE1, MTE2, event_id_next + 2);
                if (TB) {
                    CopyGmToCbufNd2Nz(l1_buf_b_next,       // dst
                                      gm_b[offset_b_next], // src
                                      n_actual_next,       // nTileActual
                                      n_round_next,        // nTileCeil
                                      n,                   // nVal
                                      k_actual_next,       // dTileActual
                                      k_round_next,        // dTileCeil
                                      k);                  // dVal
                } else {
                    CopyGmToCbufNd2Nz(l1_buf_b_next,       // dst
                                      gm_b[offset_b_next], // src
                                      k_actual_next,       // nTileActual
                                      k_round_next,        // nTileCeil
                                      k,                   // nVal
                                      n_actual_next,       // dTileActual
                                      n_round_next,        // dTileCeil
                                      n);                  // dVal
                }
                SET_FLAG(MTE2, MTE1, event_id_next + 2);
            }

            for (uint32_t k_part_idx = 0; k_part_idx < k_part_loop; k_part_idx++) {
                uint32_t k0_round = (k_part_idx < k_part_loop - 1) ? k_part_len : k_round - k_part_idx * k_part_len;
                uint32_t k0_actual = (k_part_idx < k_part_loop - 1) ? k_part_len : k_actual - k_part_idx * k_part_len;

                auto mte1_mad_ping_flag = 1 - k_part_idx % 2;
                auto mte1_mad_event_id = mte1_mad_ping_flag ? EVENT_ID0 : EVENT_ID1;
                AscendC::LocalTensor<InDtype> l0a_buf = l0a_base[(k_part_idx % 2) * L0_PINGPONG_BUFFER_LEN];
                AscendC::LocalTensor<InDtype> l0b_buf = l0b_base[(k_part_idx % 2) * L0_PINGPONG_BUFFER_LEN];

                // *** load matrix A from L1 to L0A
                if (k_part_idx == 0) {
                    WAIT_FLAG(MTE2, MTE1, event_id);
                }
                WAIT_FLAG(M, MTE1, mte1_mad_event_id);
                if ((m == 1) || (m_actual == 1 && !TA)) {
                    l1_to_l0_a<ArchType::ASCEND_V220, InDtype, false, DataFormat::VECTOR, DataFormat::VECTOR>(
                        l0a_buf,
                        l1_buf_a[k_part_idx * k_part_len],
                        0,
                        (k0_round + CONST_256 - 1) / CONST_256, // repeat
                        0,
                        1, // srcStride
                        0,
                        0 // dstStride
                    );
                } else {
                    if (TA) {
                        LoadCbufToCa(l0a_buf,                                      // l0Tensor
                                     l1_buf_a[k_part_idx * k_part_len * CONST_16], // l1Tensor
                                     m_round,                                      // mTileCeil
                                     k0_round,                                     // kPartCeil
                                     k_round / CONST_16,                           // mSrcStride
                                     1,                                            // kSrcStride
                                     k0_round / CONST_16,                          // mDstStride
                                     1);                                           // kDstStride
                    } else {
                        LoadCbufToCa(l0a_buf,                                     // l0Tensor
                                     l1_buf_a[k_part_idx * k_part_len * m_round], // l1Tensor
                                     m_round,                                     // mTileCeil
                                     k0_round,                                    // kPartCeil
                                     1,                                           // mSrcStride
                                     m_round / CONST_16,                          // kSrcStride
                                     k0_round / CONST_16,                         // mDstStride
                                     1);                                          // kDstStride
                    }
                }
                if (k_part_idx == k_part_loop - 1) {
                    SET_FLAG(MTE1, MTE2, event_id);
                }

                // *** load matrix B from L1 to L0B
                if (k_part_idx == 0) {
                    WAIT_FLAG(MTE2, MTE1, event_id + 2);
                }
                if (TB) {
                    LoadCbufToCb(l0b_buf,                                     // l0Tensor
                                 l1_buf_b[k_part_idx * k_part_len * n_round], // l1Tensor
                                 n_round,                                     // nTileCeil
                                 k0_round,                                    // kPartCeil
                                 1,                                           // nSrcStride
                                 n_round / CONST_16,                          // kSrcStride
                                 1,                                           // nDstStride
                                 k0_round / CONST_16);                        // kDstStride
                } else {
                    LoadCbufToCb(l0b_buf,                                      // l0Tensor
                                 l1_buf_b[k_part_idx * k_part_len * CONST_16], // l1Tensor
                                 n_round,                                      // nTileCeil
                                 k0_round,                                     // kPartCeil
                                 k_round / CONST_16,                           // nSrcStride
                                 1,                                            // kSrcStride
                                 1,                                            // nDstStride
                                 n_round / CONST_16);                          // kDstStride
                }
                if (k_part_idx == k_part_loop - 1) {
                    SET_FLAG(MTE1, MTE2, event_id + 2);
                }

                SET_FLAG(MTE1, M, mte1_mad_event_id);
                WAIT_FLAG(MTE1, M, mte1_mad_event_id);

                bool init_c = (k_idx == 0 && k_part_idx == 0);
                if (init_c) {
                    WAIT_FLAG(FIX, M, EVENT_ID0);
                }

                if (m != 1 && m_actual == 1 && TA) {
                    Mad(l0c_buf,   // c
                        l0a_buf,   // a
                        l0b_buf,   // b
                        CONST_16,  // mTileActual
                        n_actual,  // nTileActual
                        k0_actual, // kTileActual
                        init_c);   // initC
                } else {
                    Mad(l0c_buf,   // c
                        l0a_buf,   // a
                        l0b_buf,   // b
                        m_actual,  // mTileActual
                        n_actual,  // nTileActual
                        k0_actual, // kTileActual
                        init_c);   // initC
                }

                AscendC::PipeBarrier<PIPE_M>();
                SET_FLAG(M, MTE1, mte1_mad_event_id);
            }

            ping_flag = 1 - ping_flag;
        }

        SET_FLAG(M, FIX, EVENT_ID0);
        WAIT_FLAG(M, FIX, EVENT_ID0);

        // copy from L0C to gm
        CopyCcToGm(gm_c[offset_c], // dst
                   l0c_buf,        // src
                   m_actual,       // mTileActual
                   n_actual,       // nTileActual
                   m_round,        // mTileCeil
                   n);             // nActual
        SET_FLAG(FIX, M, EVENT_ID0);
    }

    WAIT_FLAG(MTE1, MTE2, EVENT_ID0);
    WAIT_FLAG(MTE1, MTE2, EVENT_ID1);
    WAIT_FLAG(MTE1, MTE2, EVENT_ID2);
    WAIT_FLAG(MTE1, MTE2, EVENT_ID3);
    WAIT_FLAG(M, MTE1, EVENT_ID0);
    WAIT_FLAG(M, MTE1, EVENT_ID1);
    WAIT_FLAG(FIX, M, EVENT_ID0);
    AscendC::PipeBarrier<PIPE_ALL>();
}

extern "C" __global__ __aicore__ void pp_matmul_accum_atomic(__gm__ uint8_t *__restrict__ gm_a,
                                                             __gm__ uint8_t *__restrict__ gm_b,
                                                             __gm__ uint8_t *__restrict__ gm_c,
                                                             __gm__ uint8_t *__restrict__ gm_placeholder,
                                                             __gm__ uint8_t *__restrict__ gm_tiling_data)
{
    PpMatmulAccumAtomic<0, false, false, half, float, float> matmul_000001; // swizzleDir[0] transA[0] transB[0] DtypeA[001]
    PpMatmulAccumAtomic<1, false, false, half, float, float> matmul_100001; // swizzleDir[1] transA[0] transB[0] DtypeA[001]
    PpMatmulAccumAtomic<0, true, false, half, float, float> matmul_010001;  // swizzleDir[0] transA[1] transB[0] DtypeA[001]
    PpMatmulAccumAtomic<1, true, false, half, float, float> matmul_110001;  // swizzleDir[1] transA[1] transB[0] DtypeA[001]
    PpMatmulAccumAtomic<0, false, true, half, float, float> matmul_001001;  // swizzleDir[0] transA[0] transB[1] DtypeA[001]
    PpMatmulAccumAtomic<1, false, true, half, float, float> matmul_101001;  // swizzleDir[1] transA[0] transB[1] DtypeA[001]
    PpMatmulAccumAtomic<0, true, true, half, float, float> matmul_011001;   // swizzleDir[0] transA[1] transB[1] DtypeA[001]
    PpMatmulAccumAtomic<1, true, true, half, float, float> matmul_111001;   // swizzleDir[1] transA[1] transB[1] DtypeA[001]

    PpMatmulAccumAtomic<0, false, false, __bf16, float, float> matmul_000010; // swizzleDir[0] transA[0] transB[0] DtypeA[010]
    PpMatmulAccumAtomic<1, false, false, __bf16, float, float> matmul_100010; // swizzleDir[1] transA[0] transB[0] DtypeA[010]
    PpMatmulAccumAtomic<0, true, false, __bf16, float, float> matmul_010010;  // swizzleDir[0] transA[1] transB[0] DtypeA[010]
    PpMatmulAccumAtomic<1, true, false, __bf16, float, float> matmul_110010;  // swizzleDir[1] transA[1] transB[0] DtypeA[010]
    PpMatmulAccumAtomic<0, false, true, __bf16, float, float> matmul_001010;  // swizzleDir[0] transA[0] transB[1] DtypeA[010]
    PpMatmulAccumAtomic<1, false, true, __bf16, float, float> matmul_101010;  // swizzleDir[1] transA[0] transB[1] DtypeA[010]
    PpMatmulAccumAtomic<0, true, true, __bf16, float, float> matmul_011010;   // swizzleDir[0] transA[1] transB[1] DtypeA[010]
    PpMatmulAccumAtomic<1, true, true, __bf16, float, float> matmul_111010;   // swizzleDir[1] transA[1] transB[1] DtypeA[010]

    SetPadding<uint64_t>((uint64_t)0);
    SetNdpara(1, 0, 0);
    AscendC::SetAtomicAdd<float>();
    AscendC::SetMaskNorm();

    // get tiling args
    auto tiling_data = reinterpret_cast<__gm__ AsdOps::PpMatmulTilingData *>(gm_tiling_data);
    uint32_t masked_key = tiling_data->tilingKey >> 10;

    switch (masked_key) {
        case 0b000001: // SwizzleDir[0] TransA[0] TransB[0] DtypeA[001]
            matmul_000001.Init(gm_a, gm_b, gm_c, gm_tiling_data);
            matmul_000001.Run();
            break;
        case 0b010001: // swizzleDir[0] transA[1] transB[0]
            matmul_010001.Init(gm_a, gm_b, gm_c, gm_tiling_data);
            matmul_010001.Run();
            break;
        case 0b001001: // swizzleDir[0] transA[0] transB[1]
            matmul_001001.Init(gm_a, gm_b, gm_c, gm_tiling_data);
            matmul_001001.Run();
            break;
        case 0b011001: // swizzleDir[0] transA[1] transB[1]
            matmul_011001.Init(gm_a, gm_b, gm_c, gm_tiling_data);
            matmul_011001.Run();
            break;
        case 0b100001: // swizzleDir[1] transA[0] transB[0]
            matmul_100001.Init(gm_a, gm_b, gm_c, gm_tiling_data);
            matmul_100001.Run();
            break;
        case 0b110001: // swizzleDir[1] transA[1] transB[0]
            matmul_110001.Init(gm_a, gm_b, gm_c, gm_tiling_data);
            matmul_110001.Run();
            break;
        case 0b101001: // swizzleDir[1] transA[0] transB[1]
            matmul_101001.Init(gm_a, gm_b, gm_c, gm_tiling_data);
            matmul_101001.Run();
            break;
        case 0b111001: // swizzleDir[1] transA[1] transB[1]
            matmul_111001.Init(gm_a, gm_b, gm_c, gm_tiling_data);
            matmul_111001.Run();
            break;
        case 0b000010: // SwizzleDir[0] TransA[0] TransB[0] DtypeA[001]
            matmul_000010.Init(gm_a, gm_b, gm_c, gm_tiling_data);
            matmul_000010.Run();
            break;
        case 0b010010: // swizzleDir[0] transA[1] transB[0]
            matmul_010010.Init(gm_a, gm_b, gm_c, gm_tiling_data);
            matmul_010010.Run();
            break;
        case 0b001010: // swizzleDir[0] transA[0] transB[1]
            matmul_001010.Init(gm_a, gm_b, gm_c, gm_tiling_data);
            matmul_001010.Run();
            break;
        case 0b011010: // swizzleDir[0] transA[1] transB[1]
            matmul_011010.Init(gm_a, gm_b, gm_c, gm_tiling_data);
            matmul_011010.Run();
            break;
        case 0b100010: // swizzleDir[1] transA[0] transB[0]
            matmul_100010.Init(gm_a, gm_b, gm_c, gm_tiling_data);
            matmul_100010.Run();
            break;
        case 0b110010: // swizzleDir[1] transA[1] transB[0]
            matmul_110010.Init(gm_a, gm_b, gm_c, gm_tiling_data);
            matmul_110010.Run();
            break;
        case 0b101010: // swizzleDir[1] transA[0] transB[1]
            matmul_101010.Init(gm_a, gm_b, gm_c, gm_tiling_data);
            matmul_101010.Run();
            break;
        case 0b111010: // swizzleDir[1] transA[1] transB[1]
            matmul_111010.Init(gm_a, gm_b, gm_c, gm_tiling_data);
            matmul_111010.Run();
            break;
        default: break;
    }
}