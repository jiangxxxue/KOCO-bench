{
  "meta": {
    "repository": "VSLAM-LAB",
    "target_domains": [
      "计算机视觉",
      "机器人定位与导航",
      "三维重建",
      "传感器融合"
    ],
    "generation_focus": "严格的高层次领域知识问题。零琐碎内容。",
    "total_problems": 16,
    "single_answer_count": 1,
    "multiple_answer_count": 15
  },
  "problems": [
    {
      "id": 1,
      "dataset": "VSLAM-LAB",
      "instruction": "选择一个选项",
      "stem": "当EUROC数据集实现在create_calibration_yaml()中执行立体校正时，为什么要用校正后的版本物理覆盖原始RGB图像，而不是单独存储校正后的图像？\n\n- (A) 为了减少存储需求，避免重复图像存储，假设基线系统期望预校正的立体对以满足极线几何约束\n- (B) 为了通过消除基线系统中的运行时校正开销来提高处理速度\n- (C) 因为提取标定参数后不再需要原始畸变图像\n- (D) 为了保持与需要校正图像的TUM RGB-D数据集格式的兼容性",
      "explanation": "(A)正确。这个设计选择反映了立体视觉系统中的基本权衡：预校正通过确保极线是水平的来简化基线实现，从而实现高效的立体匹配。dataset_euroc.py中的代码使用cv2.stereoRectify()计算校正变换，然后使用cv2.remap()变换图像，覆盖原始图像。这假设基线期望校正后的输入（在ORB-SLAM2/3等SLAM系统中很常见）。Datasets/dataset_euroc.py（校正）和Baselines/BaselineVSLAMLab.py（执行）之间的交互显示了这种预处理契约。(B)部分正确但忽略了极线几何动机。(C)不正确——原始图像对研究可能有价值。(D)不正确——TUM和EUROC是具有不同约定的不同数据集。",
      "gt": [
        "A"
      ]
    },
    {
      "id": 2,
      "dataset": "VSLAM-LAB",
      "instruction": "选择多个选项",
      "stem": "框架支持多种传感器融合模态（mono、rgbd、stereo、mono-vi、stereo-vi）。哪些架构设计模式使基线和数据集抽象能够支持这种多模态？\n\n- (A) BaselineVSLAMLab和DatasetVSLAMLab类中的'modes'属性定义了支持的模态，实现了基线-数据集兼容性的运行时验证\n- (B) pixi.toml中的独立执行命令构建器（execute-mono、execute-rgbd、execute-stereo、execute-mono_vi）允许特定于模态的执行路径\n- (C) 标定YAML模式根据模态要求灵活包含Camera0、Camera1、IMU、Depth0和Stereo部分\n- (D) 统一的轨迹格式（ts, tx, ty, tz, qx, qy, qz, qw）在评估阶段抽象了传感器差异\n- (E) 通过C++基线实现中的虚函数实现动态多态\n- (F) DatasetVSLAMLab.write_calibration_yaml()方法接受可选的camera1、imu、rgbd、stereo参数来组合特定于模态的标定",
      "explanation": "(A)、(B)、(C)、(D)和(F)正确。这种多模态架构跨越多个文件：(A) BaselineVSLAMLab.py和DatasetVSLAMLab.py定义self.modes用于验证；(B) pixi.toml定义特定于模态的任务；(C) dataset_calibration.py提供_get_camera_yaml_section()、_get_imu_yaml_section()等；(D) metrics.py和evo_functions.py使用统一的姿态表示；(F) DatasetVSLAMLab.write_calibration_yaml()组合标定。这种设计通过将传感器配置与算法实现解耦来支持传感器融合研究。(E)不正确——Python基线使用鸭子类型，而不是C++虚函数。",
      "gt": [
        "A",
        "B",
        "C",
        "D",
        "F"
      ]
    },
    {
      "id": 4,
      "dataset": "VSLAM-LAB",
      "instruction": "选择多个选项",
      "stem": "框架实现了资源监控，在基线执行期间跟踪RAM、SWAP和GPU内存增量。什么计算机视觉和SLAM特定的挑战促使了这种多层内存监控方法？\n\n- (A) 基于深度学习的SLAM系统（DROID-SLAM、DPVO）将大型神经网络权重加载到GPU内存中，需要GPU特定的监控\n- (B) 密集重建方法在RAM中累积点云或体素网格，导致内存增长与场景大小成正比\n- (C) 闭环检测维护关键帧描述符数据库，该数据库随轨迹长度增长\n- (D) 实时约束需要监控以确保帧处理保持在时间预算内\n- (E) 束调整优化创建可能超过可用RAM的大型稀疏矩阵\n- (F) 多线程跟踪和建图线程竞争内存带宽",
      "explanation": "(A)、(B)、(C)和(E)正确。BaselineVSLAMLab.py中的monitor_memory()方法跟踪ram_inc、swap_inc和gpu_inc，因为：(A)像droidslam、dpvo、mast3rslam这样的基线使用PyTorch模型（pixi.toml显示pytorch-gpu依赖）；(B)像MonoGS这样的系统执行高斯溅射重建；(C) ORB-SLAM2/3维护DBoW2数据库；(E)像COLMAP/GLOMAP这样的系统执行大规模束调整。代码杀死超过阈值的进程以防止系统崩溃。文件：Baselines/BaselineVSLAMLab.py（监控）、Baselines/baseline_droidslam.py、Baselines/baseline_monogs.py。(D)不正确——时间预算由timeout_seconds处理，而不是内存监控。(F)不正确——不监控内存带宽，只监控容量。",
      "gt": [
        "A",
        "B",
        "C",
        "E"
      ]
    },
    {
      "id": 6,
      "dataset": "VSLAM-LAB",
      "instruction": "选择多个选项",
      "stem": "标定YAML格式包括内参（fx, fy, cx, cy）和畸变系数（k1, k2, p1, p2, k3）。这些参数如何与视觉SLAM流水线的不同阶段交互？\n\n- (A) 内参用于投影函数，在特征跟踪期间将3D点映射到2D图像坐标\n- (B) 畸变系数在图像校正预处理期间应用，为特征检测创建无畸变图像\n- (C) 主点(cx, cy)定义径向畸变校正的图像中心\n- (D) 焦距(fx, fy)决定视场角，并用于单目系统的深度估计\n- (E) 畸变参数在束调整中用于联合优化相机位姿和3D结构\n- (F) k3系数处理广角相机的鱼眼畸变",
      "explanation": "(A)、(B)、(C)和(E)正确。标定参数有多种用途：(A)相机矩阵K = [[fx, 0, cx], [0, fy, cy], [0, 0, 1]]在跟踪中投影3D点（所有基线使用）；(B) dataset_euroc.py显示cv2.initUndistortRectifyMap()使用畸变系数进行预处理；(C) (cx, cy)是畸变中心；(E)像COLMAP/ORB-SLAM2这样的系统可以在束调整中优化标定。文件：Datasets/dataset_calibration.py、Datasets/dataset_euroc.py、Baselines/baseline_orbslam2.py。(D)误导——焦距影响FoV，但单目尺度在没有额外约束的情况下不可观测。(F)不正确——k3是Brown-Conrady模型的第三个径向畸变项，不专门用于鱼眼（使用不同模型）。",
      "gt": [
        "A",
        "B",
        "C",
        "E"
      ]
    },
    {
      "id": 8,
      "dataset": "VSLAM-LAB",
      "instruction": "选择多个选项",
      "stem": "dataset_euroc.py中的IMU数据处理将时间戳从纳秒转换为秒，并格式化为9位小数。什么传感器融合和数值考虑促使了这种精度要求？\n\n- (A) 视觉-惯性融合需要相机帧（通常20-30 Hz）和IMU测量（通常200-400 Hz）之间的亚毫秒时间戳同步\n- (B) 用于位姿预测的IMU积分误差随时间二次累积，需要高时间戳精度以最小化积分漂移\n- (C) VIO系统中的卡尔曼滤波器更新使用时间戳差异计算状态转移矩阵，精度影响协方差传播\n- (D) 九位小数（纳秒精度）匹配原始EUROC数据集格式以实现无损转换\n- (E) GPU浮点运算需要扩展精度以避免矩阵运算中的灾难性抵消\n- (F) evo评估工具需要纳秒精度进行轨迹对齐",
      "explanation": "(A)、(B)、(C)和(D)正确。dataset_euroc.py中的create_imu_csv()方法将纳秒转换为带9位小数的秒，因为：(A) VIO系统如ORB-SLAM3、OKVIS2需要精确同步——相机约20Hz，IMU约200Hz意味着IMU样本间约5ms；(B) IMU预积分（VIO中使用）复合误差；(C) EKF/UKF状态预测在指数映射中使用Δt；(D)保留原始精度。文件：Datasets/dataset_euroc.py、Baselines/baseline_orbslam3.py、Baselines/baseline_okvis2.py。(E)不正确——GPU精度与时间戳精度分离。(F)不正确——evo使用秒级精度。",
      "gt": [
        "A",
        "B",
        "C",
        "D"
      ]
    },
    {
      "id": 10,
      "dataset": "VSLAM-LAB",
      "instruction": "选择多个选项",
      "stem": "框架支持传统SLAM系统（ORB-SLAM2/3）和基于学习的系统（DROID-SLAM、DPVO）。这些范式之间的什么基本算法差异反映在pixi.toml的依赖要求中？\n\n- (A) 基于学习的系统需要PyTorch和CUDA用于运行时跟踪和建图期间的神经网络推理\n- (B) 传统系统需要Eigen和OpenCV用于手工特征提取和几何优化\n- (C) 基于学习的系统需要lietorch用于SE(3)位姿上的可微李群操作\n- (D) 传统系统需要Pangolin用于优化图的可视化\n- (E) 基于学习的系统由于帧的批处理需要更大的RAM分配\n- (F) 传统系统需要Ceres或g2o用于束调整中的非线性最小二乘优化",
      "explanation": "(A)、(B)、(C)和(D)正确。pixi.toml依赖揭示算法差异：(A) droidslam-dev、dpvo-dev、mast3rslam-dev需要pytorch-gpu、cuda-compiler用于学习特征提取和匹配；(B) orbslam2-dev需要eigen、opencv用于ORB特征和几何求解器；(C) droidslam、mast3rslam需要lietorch用于可微位姿优化；(D) orbslam2-dev、dpvo-dev需要pangolin用于可视化。文件：pixi.toml、Baselines/baseline_droidslam.py、Baselines/baseline_orbslam2.py。(E)不正确——批处理不是SLAM的区分因素（两者都顺序处理）。(F)部分正确但依赖中未明确——ORB-SLAM2内部使用g2o。",
      "gt": [
        "A",
        "B",
        "C",
        "D"
      ]
    },
    {
      "id": 12,
      "dataset": "VSLAM-LAB",
      "instruction": "选择多个选项",
      "stem": "框架提供来自不同环境（室内、室外、水下、空中、医疗）的数据集。这些不同环境对视觉SLAM系统提出了什么特定领域的挑战？\n\n- (A) 水下环境（洞穴、珊瑚礁）具有不均匀照明、颜色衰减和粒子散射，降低特征检测\n- (B) 空中无人机数据集（euroc）涉及快速运动和旋转，挑战运动模糊处理和IMU集成\n- (C) 医疗内窥镜数据集（hamlyn）具有镜面反射、可变形组织和有限视场\n- (D) 室内合成数据集（replica、nuim）提供完美真值但缺乏真实传感器噪声和运动模糊\n- (E) 室外车辆数据集（kitti、rover）具有动态物体和跨季节的不同照明\n- (F) 所有环境需要相同的相机标定程序",
      "explanation": "(A)、(B)、(C)、(D)和(E)正确。多样化数据集测试不同失败模式：(A) Datasets/dataset_caves.py、dataset_reefslam.py解决水下挑战；(B) Datasets/dataset_euroc.py提供高速率IMU用于快速运动；(C) Datasets/dataset_hamlyn.py测试医疗场景；(D) Datasets/dataset_replica.py、dataset_nuim.py是合成的；(E) Datasets/dataset_kitti.py、dataset_rover.py测试室外鲁棒性。这种多样性是有意的——SLAM系统必须跨领域泛化。文件：Datasets/（各种数据集实现）、README.md。(F)不正确——不同环境需要不同标定方法（例如水下需要折射率校正）。",
      "gt": [
        "A",
        "B",
        "C",
        "D",
        "E"
      ]
    },
    {
      "id": 14,
      "dataset": "VSLAM-LAB",
      "instruction": "选择多个选项",
      "stem": "框架使用evo工具的TUM轨迹格式（timestamp tx ty tz qx qy qz qw）作为标准输出格式。什么属性使这种格式适合SLAM评估？\n\n- (A) 四元数表示（qx, qy, qz, qw）避免万向节锁并为方向提供平滑插值\n- (B) 时间戳支持不同采样率的估计轨迹和真值轨迹之间的时间对齐\n- (C) 格式分离平移和旋转，支持独立分析平移和旋转误差\n- (D) 格式易于人类阅读且易于被标准工具（pandas、numpy）解析\n- (E) 四元数提供旋转的最小3参数表示\n- (F) 格式包括速度和加速度用于动态分析",
      "explanation": "(A)、(B)、(C)和(D)正确。evo_functions.py和metrics.py中使用的TUM格式具有这些优势：(A)四元数避免欧拉角奇异性并支持SLERP插值；(B)时间戳允许evo_ape在不同采样率下关联位姿（--t_max_diff参数）；(C)独立的tx,ty,tz和qx,qy,qz,qw支持独立计算平移ATE和旋转误差；(D) CSV格式带空格分隔符易于处理（read_trajectory_csv、save_trajectory_csv）。文件：Evaluate/evo_functions.py、Evaluate/metrics.py、utilities.py。(E)不正确——四元数使用4个参数（过参数化但避免奇异性）。(F)不正确——格式只包括位姿，不包括导数。",
      "gt": [
        "A",
        "B",
        "C",
        "D"
      ]
    },
    {
      "id": 16,
      "dataset": "VSLAM-LAB",
      "instruction": "选择多个选项",
      "stem": "框架的实验日志分别跟踪SUCCESS（布尔值）和COMMENTS（字符串）字段。这些字段帮助诊断SLAM系统中的什么失败模式？\n\n- (A) 超过内存阈值（在COMMENTS中跟踪特定的RAM/SWAP/GPU值）\n- (B) 进程超时，表示系统未能在时间限制内完成\n- (C) 缺少轨迹输出文件，表示基线崩溃或初始化失败\n- (D) 评估失败，基线成功但轨迹对齐失败\n- (E) C++基线中的编译错误\n- (F) 数据集下载期间的网络故障",
      "explanation": "(A)、(B)、(C)和(D)正确。BaselineVSLAMLab.py中的execute()方法设置success_flag[0] = False并为以下情况添加COMMENTS：(A)内存阈值违规（monitor_memory）；(B)超时（subprocess.TimeoutExpired）；(C)缺少轨迹文件检查；(D)评估失败在EVALUATION列中单独跟踪。vslamlab_run.py将这些记录到exp_log CSV。这些诊断信息帮助研究人员理解实验失败的原因——对调试SLAM系统至关重要。文件：Baselines/BaselineVSLAMLab.py、vslamlab_run.py、Evaluate/evaluate_functions.py。(E)不正确——编译在安装期间发生，不在执行期间。(F)不正确——下载在实验之前发生。",
      "gt": [
        "A",
        "B",
        "C",
        "D"
      ]
    },
    {
      "id": 18,
      "dataset": "VSLAM-LAB",
      "instruction": "选择多个选项",
      "stem": "框架的标定YAML包括IMU变换矩阵（T_BS），表示body到sensor的变换。这个外参标定如何在视觉-惯性SLAM系统中使用？\n\n- (A) 将IMU测量从IMU坐标系变换到相机坐标系，用于EKF/UKF状态估计器中的传感器融合\n- (B) 在计算视觉-惯性约束时补偿IMU和相机之间的空间偏移\n- (C) 补偿相机和IMU测量之间的时间偏移\n- (D) 在相机参考系中支持关键帧之间的IMU预积分\n- (E) 随时间校正IMU偏差漂移\n- (F) 将真值轨迹从body坐标系变换到相机坐标系用于评估",
      "explanation": "(A)、(B)、(D)和(F)正确。dataset_euroc.py create_calibration_yaml()中的T_BS变换在VIO中有多种用途：(A) ORB-SLAM3、OKVIS2在相机坐标系中融合IMU，需要变换；(B) T_BS的空间偏移（平移分量）影响视觉特征和IMU测量之间的关系；(D) IMU预积分（在基于优化的VIO中使用）在body坐标系中积分IMU，然后变换到相机坐标系；(F)真值通常在body坐标系中，需要变换用于相机坐标系轨迹比较。文件：Datasets/dataset_euroc.py、Baselines/baseline_orbslam3.py、Baselines/baseline_okvis2.py。(C)不正确——时间偏移单独处理（不在T_BS中）。(E)不正确——偏差在线估计，不通过外参校正。",
      "gt": [
        "A",
        "B",
        "D",
        "F"
      ]
    },
    {
      "id": 20,
      "dataset": "VSLAM-LAB",
      "instruction": "选择多个选项",
      "stem": "框架支持Structure from Motion（SfM）系统如COLMAP和GLOMAP以及SLAM系统。什么基本算法差异区分SfM和SLAM？\n\n- (A) SfM处理无序图像集合，在批量优化中联合求解相机位姿和3D结构\n- (B) SLAM处理顺序视频流，实时或近实时增量更新位姿和地图\n- (C) SfM通常对所有图像使用全局束调整，而SLAM对最近关键帧使用局部束调整\n- (D) SfM需要闭环检测，而SLAM不需要\n- (E) SfM可以利用整个集合的图像检索和匹配，而SLAM主要匹配连续帧\n- (F) SfM系统总是产生比SLAM系统更密集的重建",
      "explanation": "(A)、(B)、(C)和(E)正确。区别在基线实现中明显：(A) COLMAP/GLOMAP（Baselines/baseline_colmap.py、baseline_glomap.py）执行批量重建；(B) DROID-SLAM、ORB-SLAM2（baseline_droidslam.py、baseline_orbslam2.py）处理顺序帧；(C) SfM联合优化所有相机，SLAM使用滑动窗口优化；(E) SfM使用词汇树进行宽基线匹配，SLAM使用时间接近性。README区分系统类型：'SfM' vs 'VSLAM'。文件：Baselines/baseline_colmap.py、Baselines/baseline_orbslam2.py、README.md。(D)不正确——SLAM也使用闭环。(F)不正确——密度取决于具体方法，不取决于范式。",
      "gt": [
        "A",
        "B",
        "C",
        "E"
      ]
    },
    {
      "id": 22,
      "dataset": "VSLAM-LAB",
      "instruction": "选择多个选项",
      "stem": "框架的RGB-D数据集在标定中包括depth_factor参数。这个缩放因子在深度传感器处理中扮演什么角色？\n\n- (A) 将传感器的整数深度值转换为以米为单位的度量深度（例如depth_meters = depth_raw / depth_factor）\n- (B) 考虑不同传感器的不同深度编码方案（例如Kinect使用5000，RealSense使用1000）\n- (C) 补偿随距离二次增加的深度测量噪声\n- (D) 通过缩放支持深度图与RGB图像的对齐\n- (E) 归一化深度值用于神经网络输入\n- (F) 校正结构光传感器中的系统深度偏差",
      "explanation": "(A)和(B)正确。dataset_calibration.py _get_rgbd_yaml_section()中的depth_factor将原始深度值转换为米：(A)深度传感器将深度存储为16位整数以节省带宽，需要缩放到度量单位；(B)不同传感器使用不同尺度（TUM RGB-D使用5000，ETH使用5000，如dataset_rgbdtum.py和dataset_eth.py所示）。这对需要度量深度进行3D重建的RGB-D SLAM系统至关重要。文件：Datasets/dataset_calibration.py、Datasets/dataset_rgbdtum.py、Datasets/dataset_eth.py。(C)不正确——噪声特性不通过常数因子校正。(D)不正确——对齐使用外参标定，不使用深度缩放。(E)不正确——神经网络归一化是分离的。(F)不正确——系统偏差需要逐像素校正，不是全局因子。",
      "gt": [
        "A",
        "B"
      ]
    },
    {
      "id": 24,
      "dataset": "VSLAM-LAB",
      "instruction": "选择多个选项",
      "stem": "框架的实验工作流为每次运行跟踪TIME、RAM、SWAP和GPU指标。这些性能指标为SLAM系统分析提供什么见解？\n\n- (A) TIME揭示计算效率和实时能力，对需要在线操作的机器人应用至关重要\n- (B) RAM使用表示地图大小增长和内存管理效率，对长期自主性很重要\n- (C) GPU内存揭示基于学习系统中神经网络推理的成本\n- (D) SWAP使用表示可能导致系统不稳定或性能下降的内存压力\n- (E) 这些指标支持部署的硬件需求规范\n- (F) TIME直接与轨迹精度相关",
      "explanation": "(A)、(B)、(C)、(D)和(E)正确。vslamlab_run.py记录这些指标，因为：(A) TIME确定系统是否满足实时约束（例如机器人的30Hz）；(B) RAM增长表示地图管理效率——对长任务至关重要；(C) GPU内存揭示DROID-SLAM、DPVO中的神经网络成本；(D) SWAP表示降低性能的内存压力；(E)指标通知部署决策（例如嵌入式vs服务器）。BaselineVSLAMLab.py中的monitor_memory()跟踪增量使用。文件：vslamlab_run.py、Baselines/BaselineVSLAMLab.py。(F)不正确——精度和速度通常成反比（精度-速度权衡），不直接相关。",
      "gt": [
        "A",
        "B",
        "C",
        "D",
        "E"
      ]
    },
    {
      "id": 26,
      "dataset": "VSLAM-LAB",
      "instruction": "选择多个选项",
      "stem": "框架提供基于Python（DROID-SLAM、DPVO）和基于C++（ORB-SLAM2/3）的基线实现。什么架构考虑影响SLAM系统实现语言的选择？\n\n- (A) C++提供确定性内存管理和更低延迟，对传统几何SLAM中的实时性能至关重要\n- (B) Python支持快速原型设计和与深度学习框架（PyTorch）的轻松集成，有利于基于学习的方法\n- (C) C++允许对多线程和SIMD优化进行细粒度控制，用于特征提取和匹配\n- (D) Python的GIL（全局解释器锁）阻止真正的并行性，使其不适合SLAM\n- (E) C++基线可以部署在Python支持有限的嵌入式系统上\n- (F) Python为优化算法提供更好的数值稳定性",
      "explanation": "(A)、(B)、(C)和(E)正确。语言选择反映不同优先级：(A) ORB-SLAM2（baseline_orbslam2.py显示C++编译）需要<10ms延迟用于实时跟踪；(B) DROID-SLAM（baseline_droidslam.py）使用PyTorch用于学习特征；(C) ORB-SLAM2使用SSE/AVX用于ORB提取；(E)嵌入式部署偏好C++。pixi.toml显示：C++基线需要编译器、cmake；Python基线需要pytorch-gpu。文件：Baselines/baseline_orbslam2.py、Baselines/baseline_droidslam.py、pixi.toml。(D)不正确——Python SLAM系统使用C++扩展或多进程绕过GIL。(F)不正确——数值稳定性取决于算法，不取决于语言。",
      "gt": [
        "A",
        "B",
        "C",
        "E"
      ]
    },
    {
      "id": 28,
      "dataset": "VSLAM-LAB",
      "instruction": "选择多个选项",
      "stem": "框架支持具有不同相机模型的数据集（目前全部为Pinhole）。如果支持鱼眼或全向相机，需要以不同方式处理什么几何属性？\n\n- (A) 投影和反投影函数需要考虑非线性畸变模型（例如等距、立体投影）\n- (B) 特征检测需要处理图像上的不同分辨率（鱼眼中心更高）\n- (C) 立体匹配的极线几何不再遵循直线，需要弯曲的极线曲线\n- (D) 视场可能超过180度，需要特殊处理图像边界附近的特征\n- (E) 束调整需要不同的相机内参参数化\n- (F) 所有SLAM算法需要完全重写",
      "explanation": "(A)、(B)、(C)、(D)和(E)正确。支持非针孔相机需要：(A)不同的投影模型（dataset_calibration.py需要'Pinhole'之外的新模型）；(B)鱼眼具有非均匀分辨率；(C)极线几何变为非线性（影响dataset_euroc.py中的立体校正）；(D)宽FoV需要处理环绕的特征；(E)束调整参数化改变（影响COLMAP等系统）。README显示所有当前数据集使用'Pinhole'模型。文件：Datasets/dataset_calibration.py、Datasets/dataset_euroc.py、README.md。(F)不正确——许多SLAM算法可以通过改变投影函数适应不同相机模型，不需要完全重写。",
      "gt": [
        "A",
        "B",
        "C",
        "D",
        "E"
      ]
    },
    {
      "id": 30,
      "dataset": "VSLAM-LAB",
      "instruction": "选择多个选项",
      "stem": "框架的架构将数据集预处理（下载、标定、真值）与基线执行分离。这种分离提供什么软件工程和研究优势？\n\n- (A) 数据集可以预处理一次并在多个基线评估中重用，避免冗余计算\n- (B) 数据集实现可以独立于基线实现开发和测试\n- (C) 可以添加新基线而无需修改数据集代码，遵循开闭原则\n- (D) 预处理可以跨多个数据集并行化，而基线顺序运行\n- (E) 分离支持独立于基线版本的数据集版本控制\n- (F) 预处理消除基线中的所有运行时计算",
      "explanation": "(A)、(B)、(C)、(D)和(E)正确。架构（DatasetVSLAMLab.py vs BaselineVSLAMLab.py）提供：(A) download_sequence()运行一次，多个基线使用相同的预处理数据；(B) dataset_euroc.py可以在没有任何基线的情况下测试；(C)添加baseline_newslam.py不需要数据集更改；(D)数据集可以在顺序基线执行之前并行下载；(E)数据集版本（例如带TUM真值的EUROC）独立于基线版本。这遵循关注点分离和依赖倒置原则。文件：Datasets/DatasetVSLAMLab.py、Baselines/BaselineVSLAMLab.py、vslamlab_run.py。(F)不正确——基线仍执行特征提取、跟踪、建图等。",
      "gt": [
        "A",
        "B",
        "C",
        "D",
        "E"
      ]
    }
  ]
}