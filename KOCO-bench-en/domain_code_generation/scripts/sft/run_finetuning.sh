#!/bin/bash
#ä»£ç åº“ NTP ç»­è®­è„šæœ¬ï¼ˆé€‚é… finetuning.pyï¼‰

# ä¸¥æ ¼æ¨¡å¼ï¼šé‡é”™ç«‹å³é€€å‡º
set -euo pipefail

# ========= åŸºç¡€è·¯å¾„ =========
MODEL_PATH="/home/shixianjie/models/Qwen2.5-Coder-7B-Instruct"
FRAMEWORK="raganything"
DATA_PATH="../data/${FRAMEWORK}/${FRAMEWORK}_training_dataset.jsonl"
OUTPUT_DIR="../models/qwen2.5-coder-7b-${FRAMEWORK}-sft"

# ========= è®­ç»ƒå‚æ•°ï¼ˆNTP ä¼˜åŒ–ï¼‰=========
MAX_SEQ_LENGTH=2048
BATCH_SIZE=2
GRADIENT_ACCUMULATION=4
LEARNING_RATE=5e-6
NUM_EPOCHS=2
WARMUP_RATIO=0.03
KEEP_FILE_TYPES="python,shell,yaml,markdown"     # ä¸ finetuning.py çš„ ModelArguments å¯¹é½
STRIDE_FRACTION=0.125                            # æ»‘çª—é‡å æ¯”ä¾‹ (= 1/8 * seq_len)
ADD_FILE_PATH_HEADER="false"                     # æ˜¯å¦åœ¨æ ·æœ¬å‰åŠ â€œ# File: pathâ€æ³¨é‡Š

# ========= GPU / ç¯å¢ƒ =========
export CUDA_VISIBLE_DEVICES=0,1,2,3
export TOKENIZERS_PARALLELISM=false
NUM_GPUS=4  # ä½¿ç”¨çš„ GPU æ•°é‡

echo "========================================================"
echo "ğŸš€ å¼€å§‹ ${FRAMEWORK} ä»£ç åº“ NTP ç»­è®­ï¼ˆfinetuning.pyï¼‰"
echo "========================================================"
echo "æ¨¡å‹: ${MODEL_PATH}"
echo "æ•°æ®: ${DATA_PATH}"
echo "è¾“å‡º: ${OUTPUT_DIR}"
echo "åºåˆ—é•¿åº¦: ${MAX_SEQ_LENGTH}"
echo "Batchå¤§å°: ${BATCH_SIZE} x ${GRADIENT_ACCUMULATION} = $((BATCH_SIZE * GRADIENT_ACCUMULATION))"
echo "å­¦ä¹ ç‡: ${LEARNING_RATE}"
echo "è®­ç»ƒè½®æ•°: ${NUM_EPOCHS}"
echo "æ–‡ä»¶ç±»å‹ç™½åå•: ${KEEP_FILE_TYPES}"
echo "æ»‘çª—é‡å æ¯”ä¾‹: ${STRIDE_FRACTION}"
echo "æ ·æœ¬å¤´éƒ¨æ³¨é‡Š: ${ADD_FILE_PATH_HEADER}"
echo "========================================================"
echo ""

mkdir -p "${OUTPUT_DIR}"

# --------- å•æœºå¤šå¡è®­ç»ƒï¼ˆDeepSpeed ZeRO-3 æ¨¡å‹åˆ†ç‰‡ï¼‰---------
# é€‚ç”¨äºï¼šæ¨¡å‹å¤ªå¤§ï¼Œå•å¡æ”¾ä¸ä¸‹ï¼Œéœ€è¦å¤šå¡ä¸€èµ·åŠ è½½æ¨¡å‹
SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
DS_CONFIG="${SCRIPT_DIR}/ds_config_zero3.json"

deepspeed --num_gpus=${NUM_GPUS} finetuning.py \
  --model_name_or_path "${MODEL_PATH}" \
  --dataset_path "${DATA_PATH}" \
  --output_dir "${OUTPUT_DIR}" \
  --deepspeed "${DS_CONFIG}" \
  --max_seq_length "${MAX_SEQ_LENGTH}" \
  --val_split_ratio 0.1 \
  --per_device_train_batch_size "${BATCH_SIZE}" \
  --per_device_eval_batch_size "${BATCH_SIZE}" \
  --gradient_accumulation_steps "${GRADIENT_ACCUMULATION}" \
  --num_train_epochs "${NUM_EPOCHS}" \
  --learning_rate "${LEARNING_RATE}" \
  --lr_scheduler_type cosine \
  --warmup_ratio "${WARMUP_RATIO}" \
  --max_grad_norm 1.0 \
  --optim adamw_torch \
  --logging_steps 10 \
  --save_steps 200 \
  --eval_steps 200 \
  --save_total_limit 3 \
  --metric_for_best_model eval_loss \
  --greater_is_better false \
  --use_wandb false \
  --fp16 false \
  --bf16 true \
  --tf32 true \
  --dataloader_num_workers 4 \
  --gradient_checkpointing true \
  --remove_unused_columns false \
  --logging_first_step true \
  --report_to none \
  --keep_file_types "${KEEP_FILE_TYPES}" \
  --stride_fraction "${STRIDE_FRACTION}" \
  --add_file_path_header "${ADD_FILE_PATH_HEADER}"

echo ""
echo "========================================================"
echo "ğŸ‰ è®­ç»ƒå®Œæˆï¼æ¨¡å‹ä¿å­˜åœ¨: ${OUTPUT_DIR}"
echo "========================================================"
