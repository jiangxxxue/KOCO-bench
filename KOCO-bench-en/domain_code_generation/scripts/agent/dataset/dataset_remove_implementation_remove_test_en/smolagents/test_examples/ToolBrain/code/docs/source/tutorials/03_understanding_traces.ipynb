{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0c5a7425-e3f6-4433-9424-504f9a340498",
   "metadata": {},
   "source": [
    "# Tutorial 2: Understanding Traces\n",
    "\n",
    "The most fundamental concept in ToolBrain's learning process is the **Trace**. A Trace is a complete, high-fidelity record of an agent's attempt to solve a task. Understanding its structure is key to debugging, creating custom reward functions, and analyzing agent behavior.\n",
    "\n",
    "This tutorial explores the `Trace` and `Turn` data structures, defined in `toolbrain/core_types.py`.\n",
    "\n",
    "## The Structure of a Trace\n",
    "\n",
    "A `Trace` is simply a list of `Turn` objects:\n",
    "\n",
    "```python\n",
    "Trace = List[Turn]\n",
    "```\n",
    "\n",
    "Each `Turn` represents a single step or interaction in the agent's execution flow. By stringing these turns together, the `Trace` provides a complete, chronological history of the agent's reasoning process.\n",
    "\n",
    "## The Anatomy of a Turn\n",
    "\n",
    "A `Turn` is a `TypedDict`, a dictionary with a defined structure. It contains the following fields, each capturing a critical piece of information:\n",
    "\n",
    "```python\n",
    "class Turn(TypedDict):\n",
    "    prompt_for_model: str\n",
    "    model_completion: str\n",
    "    parsed_completion: ParsedCompletion\n",
    "    tool_output: Optional[str]\n",
    "    action_output: Optional[str]   \n",
    "    formatted_conversation: Optional[str] \n",
    "\n",
    "```\n",
    "\n",
    "Let's break down each field:\n",
    "\n",
    "1.  **`prompt_for_model: str`**\n",
    "    - **What it is**: The exact, complete string of text that was fed into the language model at the beginning of the turn.\n",
    "    - **Why it's important**: This is the full context the LLM had. It includes the initial user query, the system prompt, and the history of all previous turns (thoughts, tool calls, and tool outputs). For RL, it is important to know precisely what the model *saw*.\n",
    "\n",
    "2.  **`model_completion: str`**\n",
    "    - **What it is**: The raw, unedited string of text generated by the language model in response to the `prompt_for_model`.\n",
    "    - **Why it's important**: This is the model's pure output, before any parsing or processing. It's the ground truth of what the model *did*. This is what gets compared against during the learning process.\n",
    "\n",
    "3.  **`parsed_completion: ParsedCompletion`**\n",
    "    - **What it is**: A dictionary that contains the structured breakdown of the `model_completion`. The `CodeAgent` parses the raw output into distinct components:\n",
    "        - **`thought`**: The agent's reasoning or plan.\n",
    "        - **`tool_code`**: The Python code the agent decided to execute.\n",
    "        - **`final_answer`**: The final answer provided by the agent.\n",
    "    - **Why it's important**: This structured data makes it easy to programmatically access the agent's actions and decisions without needing to parse the raw text yourself.\n",
    "\n",
    "4.  **`tool_output: Optional[str]`**\n",
    "    - **What it is**: A string containing the result of executing the `tool_code`. This could be the return value of a function (e.g., `'12'`) or an error message if something went wrong (e.g., `'TypeError: add() missing 1 required positional argument: 'b''`). It is `None` if no tool code was executed in the turn.\n",
    "    - **Why it's important**: This represents the feedback from the environment. The `tool_output` from the current turn is appended to the conversation history and becomes part of the `prompt_for_model` for the *next* turn, allowing the agent to react to the results of its actions.\n",
    "\n",
    "\n",
    "5.  **`action_output: Optional[str]`**\n",
    "    - **What it is**: The result from executing the tool code (if any)\n",
    ".\n",
    "    - **Why it's important**: Optional data which provides additional context about the agent execution. \n",
    "\n",
    "6.  **`formatted_conversation: Optional[str]`**\n",
    "    - **What it is**: The result from executing the tool code (if any)\n",
    ".\n",
    "    - **Why it's important**: Optional data for additional context, provided by the agent.\n",
    "## Example: A Single Turn in a Trace\n",
    "\n",
    "Imagine our agent is asked to calculate `5 + 7`. The first `Turn` in the `Trace` might look something like this (simplified for clarity):\n",
    "\n",
    "```json\n",
    "{\n",
    "    \"prompt_for_model\": \"<|SYSTEM|>You are a helpful assistant...<|USER|>Use the add tool to calculate 5 + 7\",\n",
    "    \"model_completion\": \"Thought: To solve this task, I need to perform the addition operation using the add tool.\\n<code>\\nadd_result = add(5, 7)\\nprint(add_result)\\n</code>\",\n",
    "    \"parsed_completion\": {\n",
    "        \"thought\": \"To solve this task, I need to perform the addition operation using the add tool.\\n<code>\\nadd_result = add(5, 7)\\nprint(add_result)\\n</code>\",\n",
    "        \"tool_code\": \"add_result = add(5, 7)\\nprint(add_result)\",\n",
    "        \"final_answer\": null\n",
    "    },\n",
    "    \"tool_output\": \"Execution logs:\\n12\\nLast output from code snippet:\\nNone\",\n",
    "    \"action_output\": \"\",\n",
    "}\n",
    "```\n",
    "\n",
    "In the next turn, the `tool_output` (\"12\") would be added to the history, and the agent would likely produce a `final_answer`.\n",
    "\n",
    "---\n",
    "\n",
    "By preserving this detailed, step-by-step information, the `Trace` and `Turn` objects provide the data for both calculating rewards and fine-tuning the agent's underlying model. In the next tutorial, we will see how to use this data to create custom reward functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f89e8cf8-0181-4faf-8d2e-824a5d1a6b2f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5092885-8cc9-4523-b926-1bd279b32b74",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
