#!/bin/bash
# çŸ¥è¯†å†²çªæµ‹è¯•è„šæœ¬
# æµ‹è¯•LLMå…ˆåœ¨æ¡†æ¶Aä¸ŠSFTï¼Œå†åœ¨æ¡†æ¶Bä¸ŠSFTåï¼Œå›åˆ°æ¡†æ¶Açš„æ€§èƒ½è¡¨ç°
#
# ä½¿ç”¨æ–¹æ³•:
#   bash scripts/run_knowledge_conflict_test.sh

set -e

#########éœ€è¦æ‰‹åŠ¨ä¿®æ”¹çš„é…ç½®###########
### 1. åŸºç¡€æ¨¡å‹è·¯å¾„
### 2. ç¬¬ä¸€ä¸ªè®­ç»ƒçš„æ¡†æ¶ï¼ˆFIRST_FRAMEWORKï¼‰
### 3. ç¬¬äºŒä¸ªè®­ç»ƒçš„æ¡†æ¶ï¼ˆSECOND_FRAMEWORKï¼‰
### 4. æœ€ç»ˆæµ‹è¯•çš„æ¡†æ¶ï¼ˆTEST_FRAMEWORKï¼Œé€šå¸¸ä¸ç¬¬ä¸€ä¸ªæ¡†æ¶ç›¸åŒï¼‰
### 5. GPUé…ç½®
### 6. è®­ç»ƒå‚æ•°

# ========================================
# é…ç½®å˜é‡
# ========================================

# åŸºç¡€æ¨¡å‹è·¯å¾„
BASE_MODEL_PATH="/workspace/data/models/Qwen2.5-Coder-7B-Instruct"

# æ¡†æ¶é…ç½®
FIRST_FRAMEWORK="${FIRST_FRAMEWORK:-verl}"           # ç¬¬ä¸€ä¸ªè®­ç»ƒçš„æ¡†æ¶
SECOND_FRAMEWORK="${SECOND_FRAMEWORK:-open-r1}"      # ç¬¬äºŒä¸ªè®­ç»ƒçš„æ¡†æ¶
TEST_FRAMEWORK="${TEST_FRAMEWORK:-verl}"             # æµ‹è¯•æ¡†æ¶ï¼ˆé€šå¸¸ä¸ç¬¬ä¸€ä¸ªç›¸åŒï¼‰

# é¡¹ç›®æ ¹ç›®å½•
PROJECT_DIR="/KOCO-bench/KOCO-bench-en/domain_code_generation"
SCRIPT_DIR="${PROJECT_DIR}/scripts"

# æ¨¡å‹è¾“å‡ºè·¯å¾„
FIRST_SFT_MODEL="${BASE_MODEL_PATH%/}-${FIRST_FRAMEWORK}-sft"
SECOND_SFT_MODEL="${BASE_MODEL_PATH%/}-${FIRST_FRAMEWORK}-${SECOND_FRAMEWORK}-sft"

# æ¨ç†æœåŠ¡å™¨é…ç½®
SERVER_PORT=8000
SERVER_HOST="0.0.0.0"

# GPUé…ç½®
export CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7
export TOKENIZERS_PARALLELISM=false

# è®­ç»ƒå‚æ•°
MAX_SEQ_LENGTH=2048
BATCH_SIZE=4
GRADIENT_ACCUMULATION=4
LEARNING_RATE=5e-6
NUM_EPOCHS=2
WARMUP_RATIO=0.03

# ç”Ÿæˆå‚æ•°
NUM_COMPLETIONS=1
MAX_TOKENS=2048
TEMPERATURE=0.0
TOP_P=1.0

# ========================================
# é¢œè‰²è¾“å‡º
# ========================================
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
CYAN='\033[0;36m'
BOLD='\033[1m'
NC='\033[0m' # No Color

# ========================================
# è¾…åŠ©å‡½æ•°
# ========================================

print_header() {
    echo ""
    echo "============================================================"
    echo -e "${BOLD}${CYAN}$1${NC}"
    echo "============================================================"
    echo ""
}

print_step() {
    echo ""
    echo -e "${BOLD}${BLUE}### $1${NC}"
    echo ""
}

print_success() {
    echo -e "${GREEN}âœ… $1${NC}"
}

print_error() {
    echo -e "${RED}âŒ $1${NC}"
}

print_warning() {
    echo -e "${YELLOW}âš ï¸  $1${NC}"
}

# åœæ­¢æ¨ç†æœåŠ¡å™¨
stop_inference_server() {
    local pid_file="${SCRIPT_DIR}/logs/inference_server.pid"
    if [ -f "$pid_file" ]; then
        local pid=$(cat "$pid_file")
        if ps -p "$pid" > /dev/null 2>&1; then
            echo "åœæ­¢æ¨ç†æœåŠ¡å™¨ (PID: $pid)..."
            kill "$pid" 2>/dev/null || true
            sleep 2
            rm -f "$pid_file"
            print_success "æ¨ç†æœåŠ¡å™¨å·²åœæ­¢"
        fi
    fi
}

# ========================================
# ä¸»æµç¨‹å¼€å§‹
# ========================================

print_header "ğŸ§ª çŸ¥è¯†å†²çªæµ‹è¯•å®éªŒ"

echo "å®éªŒé…ç½®:"
echo "  åŸºç¡€æ¨¡å‹: ${BASE_MODEL_PATH}"
echo "  ç¬¬ä¸€æ¬¡è®­ç»ƒæ¡†æ¶: ${FIRST_FRAMEWORK}"
echo "  ç¬¬äºŒæ¬¡è®­ç»ƒæ¡†æ¶: ${SECOND_FRAMEWORK}"
echo "  æµ‹è¯•æ¡†æ¶: ${TEST_FRAMEWORK}"
echo "  ç¬¬ä¸€æ¬¡SFTè¾“å‡º: ${FIRST_SFT_MODEL}"
echo "  ç¬¬äºŒæ¬¡SFTè¾“å‡º: ${SECOND_SFT_MODEL}"
echo ""
echo "å®éªŒæµç¨‹:"
echo "  1ï¸âƒ£  å‡†å¤‡ç¬¬ä¸€ä¸ªæ¡†æ¶ (${FIRST_FRAMEWORK}) çš„è®­ç»ƒæ•°æ®"
echo "  2ï¸âƒ£  ç¬¬ä¸€æ¬¡SFTè®­ç»ƒ (${BASE_MODEL_PATH} â†’ ${FIRST_FRAMEWORK})"
echo "  3ï¸âƒ£  å‡†å¤‡ç¬¬äºŒä¸ªæ¡†æ¶ (${SECOND_FRAMEWORK}) çš„è®­ç»ƒæ•°æ®"
echo "  4ï¸âƒ£  ç¬¬äºŒæ¬¡SFTè®­ç»ƒ (${FIRST_FRAMEWORK}-SFT â†’ ${SECOND_FRAMEWORK})"
echo "  5ï¸âƒ£  åœ¨æµ‹è¯•æ¡†æ¶ (${TEST_FRAMEWORK}) ä¸Šå‡†å¤‡è¯„æµ‹æ•°æ®"
echo "  6ï¸âƒ£  å¯åŠ¨æ¨ç†æœåŠ¡å™¨ (ä½¿ç”¨æœ€ç»ˆæ¨¡å‹)"
echo "  7ï¸âƒ£  æ‰¹é‡ä»£ç ç”Ÿæˆ"
echo "  8ï¸âƒ£  æ‰¹é‡æ‰§è¡Œè¯„ä¼°"
echo "  9ï¸âƒ£  èšåˆè¯„ä¼°æŒ‡æ ‡"
echo ""

read -p "æŒ‰å›è½¦é”®ç»§ç»­ï¼Œæˆ– Ctrl+C å–æ¶ˆ..."

# ========================================
# é˜¶æ®µ1ï¼šå‡†å¤‡ç¬¬ä¸€ä¸ªæ¡†æ¶çš„è®­ç»ƒæ•°æ®
# ========================================

print_header "é˜¶æ®µ 1/9: å‡†å¤‡ ${FIRST_FRAMEWORK} æ¡†æ¶çš„è®­ç»ƒæ•°æ®"

print_step "1.1 è§£æç®—æ³•æ ¸å¿ƒæ–¹æ³•"
cd "${SCRIPT_DIR}"
FRAMEWORK="${FIRST_FRAMEWORK}" bash run_parse_algorithm_methods.sh
print_success "è§£æå®Œæˆ"

print_step "1.2 æ„å»ºæç¤ºè¯"
FRAMEWORK="${FIRST_FRAMEWORK}" bash run_prompts_construction.sh
print_success "æç¤ºè¯æ„å»ºå®Œæˆ"

print_step "1.3 æ„å»ºè®­ç»ƒæ•°æ®é›†"
cd "${SCRIPT_DIR}/sft"

# æ£€æŸ¥å¹¶è®¾ç½®æ­£ç¡®çš„è·¯å¾„
FIRST_REPO_NAME="${FIRST_FRAMEWORK}-main"
FIRST_SOURCE_DIR="${PROJECT_DIR}/${FIRST_FRAMEWORK}/knowledge_corpus/${FIRST_REPO_NAME}"
FIRST_OUTPUT_DIR="${SCRIPT_DIR}/data/${FIRST_FRAMEWORK}"
FIRST_TRAINING_DATA="${FIRST_OUTPUT_DIR}/${FIRST_FRAMEWORK}_training_dataset.jsonl"

if [ ! -d "$FIRST_SOURCE_DIR" ]; then
    print_error "æºç›®å½•ä¸å­˜åœ¨: ${FIRST_SOURCE_DIR}"
    exit 1
fi

mkdir -p "$FIRST_OUTPUT_DIR"

python3 finetune_dataset_builder.py \
    --source-dir "$FIRST_SOURCE_DIR" \
    --output-file "$FIRST_TRAINING_DATA" \
    --format jsonl \
    --max-file-size 1048576

print_success "è®­ç»ƒæ•°æ®é›†æ„å»ºå®Œæˆ: ${FIRST_TRAINING_DATA}"

# ========================================
# é˜¶æ®µ2ï¼šç¬¬ä¸€æ¬¡SFTè®­ç»ƒ
# ========================================

print_header "é˜¶æ®µ 2/9: ç¬¬ä¸€æ¬¡ SFT è®­ç»ƒ (${FIRST_FRAMEWORK})"

print_step "2.1 å¼€å§‹è®­ç»ƒ"
echo "è¾“å…¥æ¨¡å‹: ${BASE_MODEL_PATH}"
echo "è®­ç»ƒæ•°æ®: ${FIRST_TRAINING_DATA}"
echo "è¾“å‡ºæ¨¡å‹: ${FIRST_SFT_MODEL}"
echo ""

mkdir -p "${FIRST_SFT_MODEL}"

cd "${SCRIPT_DIR}/sft"

python3 finetuning.py \
    --model_name_or_path "${BASE_MODEL_PATH}" \
    --dataset_path "${FIRST_TRAINING_DATA}" \
    --output_dir "${FIRST_SFT_MODEL}" \
    --max_seq_length "${MAX_SEQ_LENGTH}" \
    --val_split_ratio 0.1 \
    --per_device_train_batch_size "${BATCH_SIZE}" \
    --per_device_eval_batch_size "${BATCH_SIZE}" \
    --gradient_accumulation_steps "${GRADIENT_ACCUMULATION}" \
    --num_train_epochs "${NUM_EPOCHS}" \
    --learning_rate "${LEARNING_RATE}" \
    --lr_scheduler_type cosine \
    --warmup_ratio "${WARMUP_RATIO}" \
    --max_grad_norm 1.0 \
    --optim adamw_torch \
    --logging_steps 10 \
    --save_steps 200 \
    --eval_steps 200 \
    --save_total_limit 3 \
    --metric_for_best_model eval_loss \
    --greater_is_better false \
    --use_wandb false \
    --fp16 false \
    --bf16 true \
    --tf32 true \
    --dataloader_num_workers 4 \
    --gradient_checkpointing true \
    --remove_unused_columns false \
    --logging_first_step true \
    --report_to none \
    --keep_file_types "python,shell,yaml,markdown" \
    --stride_fraction 0.125 \
    --add_file_path_header "false"

print_success "ç¬¬ä¸€æ¬¡è®­ç»ƒå®Œæˆ: ${FIRST_SFT_MODEL}"

# ========================================
# é˜¶æ®µ3ï¼šå‡†å¤‡ç¬¬äºŒä¸ªæ¡†æ¶çš„è®­ç»ƒæ•°æ®
# ========================================

print_header "é˜¶æ®µ 3/9: å‡†å¤‡ ${SECOND_FRAMEWORK} æ¡†æ¶çš„è®­ç»ƒæ•°æ®"

print_step "3.1 è§£æç®—æ³•æ ¸å¿ƒæ–¹æ³•"
cd "${SCRIPT_DIR}"
FRAMEWORK="${SECOND_FRAMEWORK}" bash run_parse_algorithm_methods.sh
print_success "è§£æå®Œæˆ"

print_step "3.2 æ„å»ºæç¤ºè¯"
FRAMEWORK="${SECOND_FRAMEWORK}" bash run_prompts_construction.sh
print_success "æç¤ºè¯æ„å»ºå®Œæˆ"

print_step "3.3 æ„å»ºè®­ç»ƒæ•°æ®é›†"
cd "${SCRIPT_DIR}/sft"

# æ£€æŸ¥å¹¶è®¾ç½®æ­£ç¡®çš„è·¯å¾„
SECOND_REPO_NAME="${SECOND_FRAMEWORK}-main"
SECOND_SOURCE_DIR="${PROJECT_DIR}/${SECOND_FRAMEWORK}/knowledge_corpus/${SECOND_REPO_NAME}"
SECOND_OUTPUT_DIR="${SCRIPT_DIR}/data/${SECOND_FRAMEWORK}"
SECOND_TRAINING_DATA="${SECOND_OUTPUT_DIR}/${SECOND_FRAMEWORK}_training_dataset.jsonl"

if [ ! -d "$SECOND_SOURCE_DIR" ]; then
    print_error "æºç›®å½•ä¸å­˜åœ¨: ${SECOND_SOURCE_DIR}"
    exit 1
fi

mkdir -p "$SECOND_OUTPUT_DIR"

python3 finetune_dataset_builder.py \
    --source-dir "$SECOND_SOURCE_DIR" \
    --output-file "$SECOND_TRAINING_DATA" \
    --format jsonl \
    --max-file-size 1048576

print_success "è®­ç»ƒæ•°æ®é›†æ„å»ºå®Œæˆ: ${SECOND_TRAINING_DATA}"

# ========================================
# é˜¶æ®µ4ï¼šç¬¬äºŒæ¬¡SFTè®­ç»ƒ
# ========================================

print_header "é˜¶æ®µ 4/9: ç¬¬äºŒæ¬¡ SFT è®­ç»ƒ (${SECOND_FRAMEWORK})"

print_step "4.1 å¼€å§‹è®­ç»ƒï¼ˆåŸºäºç¬¬ä¸€æ¬¡è®­ç»ƒçš„æ¨¡å‹ï¼‰"
echo "è¾“å…¥æ¨¡å‹: ${FIRST_SFT_MODEL}"
echo "è®­ç»ƒæ•°æ®: ${SECOND_TRAINING_DATA}"
echo "è¾“å‡ºæ¨¡å‹: ${SECOND_SFT_MODEL}"
echo ""

mkdir -p "${SECOND_SFT_MODEL}"

cd "${SCRIPT_DIR}/sft"

python3 finetuning.py \
    --model_name_or_path "${FIRST_SFT_MODEL}" \
    --dataset_path "${SECOND_TRAINING_DATA}" \
    --output_dir "${SECOND_SFT_MODEL}" \
    --max_seq_length "${MAX_SEQ_LENGTH}" \
    --val_split_ratio 0.1 \
    --per_device_train_batch_size "${BATCH_SIZE}" \
    --per_device_eval_batch_size "${BATCH_SIZE}" \
    --gradient_accumulation_steps "${GRADIENT_ACCUMULATION}" \
    --num_train_epochs "${NUM_EPOCHS}" \
    --learning_rate "${LEARNING_RATE}" \
    --lr_scheduler_type cosine \
    --warmup_ratio "${WARMUP_RATIO}" \
    --max_grad_norm 1.0 \
    --optim adamw_torch \
    --logging_steps 10 \
    --save_steps 200 \
    --eval_steps 200 \
    --save_total_limit 3 \
    --metric_for_best_model eval_loss \
    --greater_is_better false \
    --use_wandb false \
    --fp16 false \
    --bf16 true \
    --tf32 true \
    --dataloader_num_workers 4 \
    --gradient_checkpointing true \
    --remove_unused_columns false \
    --logging_first_step true \
    --report_to none \
    --keep_file_types "python,shell,yaml,markdown" \
    --stride_fraction 0.125 \
    --add_file_path_header "false"

print_success "ç¬¬äºŒæ¬¡è®­ç»ƒå®Œæˆ: ${SECOND_SFT_MODEL}"

# ========================================
# é˜¶æ®µ5ï¼šå‡†å¤‡æµ‹è¯•æ¡†æ¶çš„è¯„æµ‹æ•°æ®
# ========================================

print_header "é˜¶æ®µ 5/9: å‡†å¤‡ ${TEST_FRAMEWORK} æ¡†æ¶çš„è¯„æµ‹æ•°æ®"

print_step "5.1 è§£æç®—æ³•æ ¸å¿ƒæ–¹æ³•"
cd "${SCRIPT_DIR}"
FRAMEWORK="${TEST_FRAMEWORK}" bash run_parse_algorithm_methods.sh
print_success "è§£æå®Œæˆ"

print_step "5.2 æ„å»ºæç¤ºè¯"
FRAMEWORK="${TEST_FRAMEWORK}" bash run_prompts_construction.sh
print_success "æç¤ºè¯æ„å»ºå®Œæˆ"

# ========================================
# é˜¶æ®µ6ï¼šå¯åŠ¨æ¨ç†æœåŠ¡å™¨
# ========================================

print_header "é˜¶æ®µ 6/9: å¯åŠ¨æ¨ç†æœåŠ¡å™¨"

# å…ˆåœæ­¢å¯èƒ½å­˜åœ¨çš„æœåŠ¡å™¨
stop_inference_server

print_step "6.1 å¯åŠ¨æ¨ç†æœåŠ¡å™¨ï¼ˆä½¿ç”¨æœ€ç»ˆè®­ç»ƒçš„æ¨¡å‹ï¼‰"
echo "æ¨¡å‹è·¯å¾„: ${SECOND_SFT_MODEL}"
echo "æœåŠ¡å™¨ç«¯å£: ${SERVER_PORT}"
echo ""

cd "${SCRIPT_DIR}/inference"

# è®¾ç½®ç¯å¢ƒå˜é‡å¹¶å¯åŠ¨æœåŠ¡å™¨
MODEL_PATH="${SECOND_SFT_MODEL}" \
SERVER_PORT="${SERVER_PORT}" \
SERVER_HOST="${SERVER_HOST}" \
bash start_inference_server.sh

print_success "æ¨ç†æœåŠ¡å™¨å·²å¯åŠ¨"

# ========================================
# é˜¶æ®µ7ï¼šæ‰¹é‡ä»£ç ç”Ÿæˆ
# ========================================

print_header "é˜¶æ®µ 7/9: æ‰¹é‡ä»£ç ç”Ÿæˆ"

print_step "7.1 ä½¿ç”¨æ¨ç†æœåŠ¡å™¨ç”Ÿæˆä»£ç "

# è®¾ç½®æ¨¡å‹åç§°ï¼ˆç”¨äºè¾“å‡ºç›®å½•ï¼‰
MODEL_NAME="$(basename ${SECOND_SFT_MODEL})"

cd "${SCRIPT_DIR}/inference"

FRAMEWORK="${TEST_FRAMEWORK}" \
MODEL_NAME="${MODEL_NAME}" \
SERVER_URL="http://localhost:${SERVER_PORT}" \
NUM_COMPLETIONS="${NUM_COMPLETIONS}" \
MAX_TOKENS="${MAX_TOKENS}" \
TEMPERATURE="${TEMPERATURE}" \
TOP_P="${TOP_P}" \
bash run_batch_code_generation_with_server.sh

print_success "ä»£ç ç”Ÿæˆå®Œæˆ"

# ========================================
# é˜¶æ®µ8ï¼šæ‰¹é‡æ‰§è¡Œè¯„ä¼°
# ========================================

print_header "é˜¶æ®µ 8/9: æ‰¹é‡æ‰§è¡Œä»£ç è¯„ä¼°"

print_step "8.1 è¿è¡Œè¯„ä¼°è„šæœ¬"

cd "${SCRIPT_DIR}"

FRAMEWORK="${TEST_FRAMEWORK}" \
MODEL_NAME="${MODEL_NAME}" \
bash run_batch_execution_evaluation_pure.sh

print_success "è¯„ä¼°å®Œæˆ"

# ========================================
# é˜¶æ®µ9ï¼šèšåˆè¯„ä¼°æŒ‡æ ‡
# ========================================

print_header "é˜¶æ®µ 9/9: èšåˆè¯„ä¼°æŒ‡æ ‡"

print_step "9.1 èšåˆæ‰€æœ‰æµ‹è¯•å®ä¾‹çš„æŒ‡æ ‡"

# è·å–æµ‹è¯•å®ä¾‹åˆ—è¡¨
TEST_DATA_DIR="${SCRIPT_DIR}/data/${TEST_FRAMEWORK}/${MODEL_NAME}"
TEST_EXAMPLES_LIST=()
while IFS= read -r file; do
    filename=$(basename "$file")
    if [[ $filename =~ algorithm_methods_data_(.+)_output\.jsonl ]]; then
        test_example="${BASH_REMATCH[1]}"
        TEST_EXAMPLES_LIST+=("$test_example")
    fi
done < <(find "$TEST_DATA_DIR" -name "algorithm_methods_data_*_output.jsonl" -type f | sort)

if [ ${#TEST_EXAMPLES_LIST[@]} -eq 0 ]; then
    print_error "æœªæ‰¾åˆ°ä»»ä½•æµ‹è¯•å®ä¾‹"
    exit 1
fi

TEST_EXAMPLES_STR="${TEST_EXAMPLES_LIST[*]}"
echo "æµ‹è¯•å®ä¾‹: ${TEST_EXAMPLES_STR}"
echo ""

cd "${SCRIPT_DIR}"

python3 aggregate_metrics.py \
    --model_dir "${TEST_DATA_DIR}" \
    --test_examples ${TEST_EXAMPLES_STR} \
    --framework "${TEST_FRAMEWORK}"

print_success "æŒ‡æ ‡èšåˆå®Œæˆ"

# ========================================
# å®éªŒå®Œæˆ
# ========================================

print_header "ğŸ‰ çŸ¥è¯†å†²çªæµ‹è¯•å®éªŒå®Œæˆï¼"

echo "å®éªŒæ€»ç»“:"
echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
echo ""
echo "è®­ç»ƒæµç¨‹:"
echo "  1. åŸºç¡€æ¨¡å‹: ${BASE_MODEL_PATH}"
echo "  2. ç¬¬ä¸€æ¬¡è®­ç»ƒ (${FIRST_FRAMEWORK}): ${FIRST_SFT_MODEL}"
echo "  3. ç¬¬äºŒæ¬¡è®­ç»ƒ (${SECOND_FRAMEWORK}): ${SECOND_SFT_MODEL}"
echo ""
echo "è¯„æµ‹ä¿¡æ¯:"
echo "  æµ‹è¯•æ¡†æ¶: ${TEST_FRAMEWORK}"
echo "  æµ‹è¯•å®ä¾‹: ${TEST_EXAMPLES_STR}"
echo "  ç»“æœç›®å½•: ${TEST_DATA_DIR}"
echo ""
echo "æ¨¡å‹è·¯å¾„:"
echo "  ç¬¬ä¸€æ¬¡SFT: ${FIRST_SFT_MODEL}"
echo "  ç¬¬äºŒæ¬¡SFT: ${SECOND_SFT_MODEL}"
echo ""
echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
echo ""

# åœæ­¢æ¨ç†æœåŠ¡å™¨
print_step "æ¸…ç†ï¼šåœæ­¢æ¨ç†æœåŠ¡å™¨"
stop_inference_server

print_success "å®éªŒå®Œæˆï¼"

exit 0
