#!/usr/bin/env python3
"""
ä½¿ç”¨ OpenRouter API ç”Ÿæˆä»£ç è¡¥å…¨
"""

import json
import os
import argparse
import time
from typing import List, Dict, Any
import logging
from openai import OpenAI

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)


def load_jsonl(file_path: str) -> List[Dict[str, Any]]:
    """åŠ è½½ JSONL æ–‡ä»¶"""
    data = []
    with open(file_path, 'r', encoding='utf-8') as f:
        for line in f:
            line = line.strip()
            if line:
                data.append(json.loads(line))
    return data


def save_jsonl(data: List[Dict[str, Any]], file_path: str):
    """ä¿å­˜ JSONL æ–‡ä»¶"""
    with open(file_path, 'w', encoding='utf-8') as f:
        for item in data:
            f.write(json.dumps(item, ensure_ascii=False) + '\n')


def generate_completions_openrouter(
    client: OpenAI,
    model: str,
    messages: List[Dict[str, str]],
    num_completions: int = 1,
    max_tokens: int = 2048,
    temperature: float = 0.7,
    top_p: float = 0.95,
    delay: float = 0.5,
    debug: bool = False
) -> tuple[List[str], List[Dict[str, Any]]]:
    """
    ä½¿ç”¨ OpenRouter API ç”Ÿæˆå¤šä¸ªè¡¥å…¨
    
    Args:
        client: OpenAI å®¢æˆ·ç«¯
        model: æ¨¡å‹åç§°
        messages: æ¶ˆæ¯åˆ—è¡¨
        num_completions: ç”Ÿæˆæ•°é‡
        max_tokens: æœ€å¤§ token æ•°
        temperature: æ¸©åº¦å‚æ•°
        top_p: top_p å‚æ•°
        delay: æ¯æ¬¡è°ƒç”¨ä¹‹é—´çš„å»¶è¿Ÿ
        debug: æ˜¯å¦å¯ç”¨è°ƒè¯•æ¨¡å¼
        
    Returns:
        (ç”Ÿæˆçš„æ–‡æœ¬åˆ—è¡¨, usage ä¿¡æ¯åˆ—è¡¨)
    """
    completions = []
    usage_list = []
    
    for i in range(num_completions):
        try:
            if debug:
                logger.info(f"  ğŸ“¤ å‘é€è¯·æ±‚ {i+1}/{num_completions}")
                logger.info(f"     æ¨¡å‹: {model}")
                logger.info(f"     æ¶ˆæ¯æ•°: {len(messages)}")
            
            response = client.chat.completions.create(
                model=model,
                messages=messages,
                max_tokens=max_tokens,
                temperature=temperature,
                top_p=top_p
            )
            
            # æå– usage ä¿¡æ¯
            usage_info = {}
            if hasattr(response, 'usage') and response.usage:
                usage_dict = response.usage.model_dump() if hasattr(response.usage, 'model_dump') else vars(response.usage)
                usage_info = {
                    'prompt_tokens': usage_dict.get('prompt_tokens', 0),
                    'completion_tokens': usage_dict.get('completion_tokens', 0),
                    'total_tokens': usage_dict.get('total_tokens', 0)
                }
            
            if debug:
                logger.info(f"  ğŸ“¥ æ”¶åˆ°å“åº”")
                logger.info(f"     Response ID: {response.id}")
                logger.info(f"     Model: {response.model}")
                logger.info(f"     Choices: {len(response.choices)}")
                if usage_info:
                    logger.info(f"     Usage: input={usage_info.get('prompt_tokens', 0)}, output={usage_info.get('completion_tokens', 0)}, total={usage_info.get('total_tokens', 0)}")
            
            # è·å–å“åº”å†…å®¹
            choice = response.choices[0]
            message = choice.message
            content = message.content
            
            # ç‰¹æ®Šå¤„ç†ï¼šæ£€æŸ¥æ˜¯å¦æœ‰æ¨ç†å†…å®¹ï¼ˆo1/o3/o4 ç³»åˆ—æ¨¡å‹ï¼‰
            # è¿™äº›æ¨¡å‹å¯èƒ½ä¼šè¿”å›ç©ºçš„ contentï¼Œä½†åœ¨å…¶ä»–å­—æ®µä¸­åŒ…å«å®é™…å†…å®¹
            if content is None or (isinstance(content, str) and len(content.strip()) == 0):
                logger.warning(f"  âš ï¸  å€™é€‰ {i+1}/{num_completions} content ä¸ºç©ºæˆ– None")
                logger.warning(f"     finish_reason: {choice.finish_reason}")
                
                # å°è¯•è·å–å®Œæ•´çš„ message ä¿¡æ¯
                message_dict = message.model_dump() if hasattr(message, 'model_dump') else vars(message)
                
                # æ£€æŸ¥æ˜¯å¦å› ä¸º token é™åˆ¶å¯¼è‡´ï¼ˆæ¨ç†æ¨¡å‹å¸¸è§é—®é¢˜ï¼‰
                if choice.finish_reason == "length":
                    logger.error(f"     âŒ Token é™åˆ¶ï¼æ¨ç†æ¨¡å‹æ¶ˆè€—äº†æ‰€æœ‰ tokens")
                    logger.error(f"     å»ºè®®ï¼šå¢åŠ  --max_tokens å‚æ•°ï¼ˆæ¨è 8192 æˆ–æ›´é«˜ï¼‰")
                    
                    # æ£€æŸ¥æ˜¯å¦æœ‰ reasoning å­—æ®µ
                    if hasattr(message, 'reasoning') and message.reasoning:
                        reasoning_len = len(message.reasoning)
                        logger.warning(f"     â„¹ï¸  å‘ç°æ¨ç†å†…å®¹ï¼ˆé•¿åº¦: {reasoning_len}ï¼‰ï¼Œä½†å®é™…ä»£ç æœªç”Ÿæˆ")
                
                # è®°å½•å®Œæ•´ä¿¡æ¯ç”¨äºè°ƒè¯•
                logger.debug(f"     å®Œæ•´ message å¯¹è±¡: {json.dumps(message_dict, ensure_ascii=False, indent=2)}")
                
                # æ£€æŸ¥æ˜¯å¦æœ‰ refusal å­—æ®µ
                if hasattr(message, 'refusal') and message.refusal:
                    logger.error(f"     âŒ æ¨¡å‹æ‹’ç»å“åº”: {message.refusal}")
                    content = ""
                else:
                    content = "" if content is None else content
            
            content = content.strip() if content else ""
            
            if not content:
                logger.warning(f"  âš ï¸  å€™é€‰ {i+1}/{num_completions} å†…å®¹ä¸ºç©º")
            
            completions.append(content)
            usage_list.append(usage_info)
            logger.info(f"  âœ… å€™é€‰ {i+1}/{num_completions} ç”ŸæˆæˆåŠŸ (é•¿åº¦: {len(content)})")
            
        except Exception as e:
            logger.error(f"  âŒ å€™é€‰ {i+1}/{num_completions} ç”Ÿæˆå¤±è´¥: {e}")
            completions.append("")
            usage_list.append({})
        
        # å»¶è¿Ÿé¿å…é™æµ
        if i < num_completions - 1:
            time.sleep(delay)
    
    return completions, usage_list


def main():
    parser = argparse.ArgumentParser(description="ä½¿ç”¨ OpenRouter API ç”Ÿæˆä»£ç è¡¥å…¨")
    parser.add_argument("--api_key", type=str, default=os.getenv("OPENROUTER_API_KEY"),
                        help="OpenRouter API Key")
    parser.add_argument("--base_url", type=str, default="https://openrouter.ai/api/v1",
                        help="OpenRouter API åŸºç¡€ URL")
    parser.add_argument("--model", type=str, default="qwen/qwen2.5-coder-7b-instruct",
                        help="æ¨¡å‹åç§°")
    parser.add_argument("--input_file", type=str, required=True,
                        help="è¾“å…¥ JSONL æ–‡ä»¶")
    parser.add_argument("--output_file", type=str, required=True,
                        help="è¾“å‡º JSONL æ–‡ä»¶")
    parser.add_argument("--num_completions", type=int, default=1,
                        help="æ¯ä¸ªæ ·æœ¬ç”Ÿæˆæ•°é‡")
    parser.add_argument("--max_tokens", type=int, default=2048,
                        help="æœ€å¤§ token æ•°")
    parser.add_argument("--temperature", type=float, default=0.7,
                        help="æ¸©åº¦å‚æ•°")
    parser.add_argument("--top_p", type=float, default=0.95,
                        help="top_p å‚æ•°")
    parser.add_argument("--delay", type=float, default=0.5,
                        help="API è°ƒç”¨å»¶è¿Ÿï¼ˆç§’ï¼‰")
    parser.add_argument("--debug", action="store_true",
                        help="å¯ç”¨è°ƒè¯•æ¨¡å¼ï¼Œæ˜¾ç¤ºè¯¦ç»†è¯·æ±‚/å“åº”ä¿¡æ¯")
    
    args = parser.parse_args()
    
    # éªŒè¯ API Key
    if not args.api_key:
        logger.error("âŒ é”™è¯¯: æœªè®¾ç½® OPENROUTER_API_KEY")
        logger.error("è¯·è¿è¡Œ: export OPENROUTER_API_KEY='your-api-key'")
        return 1
    
    # åŠ è½½æ•°æ®
    logger.info(f"ğŸ“– åŠ è½½æ•°æ®: {args.input_file}")
    input_data = load_jsonl(args.input_file)
    logger.info(f"âœ… åŠ è½½äº† {len(input_data)} ä¸ªæ ·æœ¬")
    
    # åˆå§‹åŒ–å®¢æˆ·ç«¯
    logger.info(f"ğŸ”§ åˆå§‹åŒ– OpenRouter å®¢æˆ·ç«¯")
    logger.info(f"   æ¨¡å‹: {args.model}")
    logger.info(f"   æ¯ä¸ªæ ·æœ¬ç”Ÿæˆ: {args.num_completions} ä¸ªå€™é€‰")
    
    client = OpenAI(
        api_key=args.api_key,
        base_url=args.base_url
    )
    
    # ç”Ÿæˆä»£ç 
    logger.info(f"ğŸš€ å¼€å§‹ç”Ÿæˆ...")
    logger.info("")
    
    results = []
    success_count = 0
    fail_count = 0
    total_prompt_tokens_all = 0
    total_completion_tokens_all = 0
    total_tokens_all = 0
    
    for i, sample in enumerate(input_data, 1):
        function_name = sample.get('function_name', f'function_{i}')
        logger.info(f"[{i}/{len(input_data)}] å¤„ç†: {function_name}")
        
        if 'prompt' not in sample:
            logger.warning(f"  âš ï¸  è·³è¿‡: ç¼ºå°‘ prompt å­—æ®µ")
            sample['completions'] = []
            results.append(sample)
            continue
        
        # ç”Ÿæˆè¡¥å…¨
        completions, usage_list = generate_completions_openrouter(
            client=client,
            model=args.model,
            messages=sample['prompt'],
            num_completions=args.num_completions,
            max_tokens=args.max_tokens,
            temperature=args.temperature,
            top_p=args.top_p,
            delay=args.delay,
            debug=args.debug
        )
        
        # ç»Ÿè®¡
        success = sum(1 for c in completions if c)
        fail = len(completions) - success
        success_count += success
        fail_count += fail
        
        # è®¡ç®—æ€» token ä½¿ç”¨é‡
        total_prompt_tokens = sum(u.get('prompt_tokens', 0) for u in usage_list)
        total_completion_tokens = sum(u.get('completion_tokens', 0) for u in usage_list)
        total_tokens = sum(u.get('total_tokens', 0) for u in usage_list)
        
        # ç´¯åŠ åˆ°å…¨å±€ç»Ÿè®¡
        total_prompt_tokens_all += total_prompt_tokens
        total_completion_tokens_all += total_completion_tokens
        total_tokens_all += total_tokens
        
        # ä¿å­˜ç»“æœ
        result = sample.copy()
        result['completions'] = completions
        result['usage'] = {
            'prompt_tokens': total_prompt_tokens,
            'completion_tokens': total_completion_tokens,
            'total_tokens': total_tokens,
            'per_completion': usage_list  # æ¯ä¸ªè¡¥å…¨çš„è¯¦ç»† usage
        }
        results.append(result)
        
        logger.info(f"  ğŸ“Š æˆåŠŸ: {success}/{len(completions)}")
        if total_tokens > 0:
            logger.info(f"  ğŸ”¢ Token ä½¿ç”¨: input={total_prompt_tokens}, output={total_completion_tokens}, total={total_tokens}")
        logger.info("")
    
    # ä¿å­˜ç»“æœ
    logger.info(f"ğŸ’¾ ä¿å­˜ç»“æœ: {args.output_file}")
    save_jsonl(results, args.output_file)
    
    # æ˜¾ç¤ºç»Ÿè®¡
    total = success_count + fail_count
    logger.info("")
    logger.info("=" * 60)
    logger.info("ğŸ“Š ç”Ÿæˆç»Ÿè®¡")
    logger.info("=" * 60)
    logger.info(f"æ€»æ ·æœ¬æ•°: {len(input_data)}")
    logger.info(f"æ€»ç”Ÿæˆæ•°: {total}")
    logger.info(f"âœ… æˆåŠŸ: {success_count}")
    logger.info(f"âŒ å¤±è´¥: {fail_count}")
    if total > 0:
        logger.info(f"æˆåŠŸç‡: {success_count/total*100:.1f}%")
    logger.info("")
    logger.info("ğŸ”¢ Token ä½¿ç”¨ç»Ÿè®¡:")
    logger.info(f"  è¾“å…¥ tokens: {total_prompt_tokens_all:,}")
    logger.info(f"  è¾“å‡º tokens: {total_completion_tokens_all:,}")
    logger.info(f"  æ€»è®¡ tokens: {total_tokens_all:,}")
    if len(input_data) > 0:
        logger.info(f"  å¹³å‡æ¯æ ·æœ¬: {total_tokens_all/len(input_data):.1f} tokens")
    logger.info("=" * 60)
    
    return 0


if __name__ == "__main__":
    exit(main())

