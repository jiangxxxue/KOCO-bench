# Changelog

All notable changes to Obsidian RAG-Anything project.

## [2.0.0] - 2025-01-04

### üöÄ Major Features

#### GPU-Accelerated Reranking
- **Added BGE Reranker** (`BAAI/bge-reranker-base`)
  - ~350MB model size
  - 10-50ms inference on GPU (RTX 4060)
  - +15-30% relevance improvement
  - Automatic GPU/CPU fallback
  - File: `src/bge_reranker.py`

#### Comprehensive Debug Logging
- **LLM Function Debugging** in `src/simple_raganything.py`
  - Shows prompt length and structure
  - Verifies "Source Data" context presence
  - Displays system prompt status
  - Shows first 500 chars of prompt
  - Tracks Gemini response length
  - Helps diagnose "I do not have enough information" issues

#### Gemini 2.5 Flash Integration
- **Dual LLM Setup**
  - Entity extraction: Gemini 2.5 Flash
  - Query answering: Gemini 2.5 Flash
  - Rate limits: 1,000 RPM, 1M TPM
  - Cost: ~$0.00125 per 1K tokens
  - File: `src/gemini_llm.py`

### üîß Improvements

#### Architecture
- Integrated reranker into RAG initialization
- Added lazy loading for reranker model
- Improved error handling for empty responses
- Better GPU detection and fallback logic

#### Testing
- `test_gemini_extraction.py` - Test entity extraction
- `test_gemini_on_note.py` - Test on specific notes
- `setup_reranker.py` - Automated reranker setup

#### Documentation
- **README.md** - Complete rewrite with all features
- **SOLUTION_SUMMARY.md** - Detailed solution documentation
- **QUICK_FIX_GUIDE.md** - Quick reference for common issues
- **CHANGELOG.md** - This file

### üêõ Bug Fixes

- Fixed "I do not have enough information" response issue
- Removed reranker warning messages
- Fixed encoding issues in Windows (UTF-8)
- Improved prompt formatting validation

### üé® Code Quality

- Added debug logging throughout
- Improved error messages
- Better type hints and documentation
- Modular reranker implementation

### üìä Performance

- **GPU Mode** (RTX 4060):
  - Embeddings: <15ms per batch
  - Reranking: 10-50ms per query
  - Total: 1-3s per query

- **CPU Fallback**:
  - Embeddings: ~100-200ms per batch
  - Reranking: ~200-500ms per query
  - Total: 2-5s per query

### üîÑ Breaking Changes

None - fully backward compatible with v1.0

### üì¶ New Dependencies

- `sentence-transformers` - For BGE reranker
- Already in requirements.txt, no action needed

### üéØ Migration Guide

If upgrading from v1.0:

1. Run reranker setup:
   ```bash
   python setup_reranker.py
   ```

2. Set Vertex AI API key:
   ```bash
   export VERTEX_AI_API_KEY="your-key"
   ```

3. Run normally:
   ```bash
   python run_obsidian_raganything.py
   ```

---

## [1.0.0] - 2025-01-01

### üöÄ Initial Release

#### Core Features

- **SOTA Chunking System**
  - 2K token windows
  - Wikilinks preservation
  - Metadata preservation
  - File connections tracking
  - File: `src/obsidian_chunker.py`

- **EmbeddingGemma 308M**
  - Local embedding generation
  - GPU acceleration
  - 100+ languages
  - <200MB memory usage
  - Cost-free operation

- **RAG-Anything Integration**
  - Multimodal processing
  - Images, tables, equations support
  - MinerU parser integration
  - Knowledge graph construction
  - File: `src/simple_raganything.py`

#### Infrastructure

- **Conda Environment**: `turing0.1`
- **Database Management**: Automatic detection & cleanup
- **Storage**: `./rag_storage/`

#### Documentation

- Basic README.md
- Setup scripts
- Requirements specification

---

## Versioning

This project uses [Semantic Versioning](https://semver.org/):
- **MAJOR**: Breaking changes
- **MINOR**: New features (backward compatible)
- **PATCH**: Bug fixes

## Support

- See `SOLUTION_SUMMARY.md` for detailed troubleshooting
- See `QUICK_FIX_GUIDE.md` for quick fixes
- Check debug logs: `[DEBUG LLM]` output
- Report issues with debug output

## Acknowledgments

- **RAG-Anything**: Framework by HKUDS
- **LightRAG**: Backend by HKUDS
- **EmbeddingGemma**: Embeddings by Google
- **BGE Reranker**: Reranking by BAAI
- **Gemini 2.5 Flash**: LLM by Google
