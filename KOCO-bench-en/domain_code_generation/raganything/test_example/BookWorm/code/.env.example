# LLM API Keys
OPENAI_API_KEY="your-openai-api-key-here"
ANTHROPIC_API_KEY="your-anthropic-api-key-here"
DEEPSEEK_API_KEY="your-deepseek-api-key-here"
GEMINI_API_KEY="your-gemini-api-key-here"

# Primary LLM Provider for mindmap generation
# Options: "OPENAI", "CLAUDE", "DEEPSEEK", or "GEMINI"
API_PROVIDER="OPENAI"

# LightRAG Configuration
LLM_MODEL="gpt-4o-mini"
EMBEDDING_MODEL="text-embedding-3-small"
LLM_HOST="http://localhost:11434"  # For Ollama or local hosting
EMBEDDING_HOST="http://localhost:11434"
EMBEDDING_DIM="1536"
MAX_EMBED_TOKENS="8192"
TIMEOUT="300"
EMBEDDING_TIMEOUT="600"

# LLM Generation Settings
TEMPERATURE="0.7"  # Temperature for LLM generation (0.0-2.0)
MAX_TOKENS="2000"  # Maximum tokens per LLM response

# Storage Configuration
WORKING_DIR="./workspace"
DOCUMENT_DIR="./workspace/docs"
PROCESSED_DIR="./workspace/processed"
OUTPUT_DIR="./workspace/output"

# PDF Processing
PDF_PROCESSOR="mineru"  # Options: "mineru", "docling", "pymupdf", "pdfplumber"
SKIP_PDF_CONVERSION="false"

# Logging
LOG_LEVEL="INFO"
LOG_DIR="./logs"
LOG_MAX_BYTES="10485760"  # 10MB
LOG_BACKUP_COUNT="5"

# Performance Settings
MAX_CONCURRENT_PROCESSES="4"
CHUNK_SIZE="8192"
MAX_FILE_SIZE_MB="100"
